<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://agorahub.github.io/pen0/heros.xml" rel="self" type="application/atom+xml" /><link href="https://agorahub.github.io/pen0/" rel="alternate" type="text/html" /><updated>2023-09-15T13:17:24+08:00</updated><id>https://agorahub.github.io/pen0/heros.xml</id><title type="html">The Republic of Agora | Heros</title><subtitle>UNITE THE PUBLIC ♢ VOL.32 © MMXXIII</subtitle><entry><title type="html">生成式人工智能博弈</title><link href="https://agorahub.github.io/pen0/heros/2023-04-07-JoonSungPark-a1_r-generative-agents.html" rel="alternate" type="text/html" title="生成式人工智能博弈" /><published>2023-04-07T12:00:00+08:00</published><updated>2023-04-07T12:00:00+08:00</updated><id>https://agorahub.github.io/pen0/heros/JoonSungPark-a1_r-generative-agents</id><content type="html" xml:base="https://agorahub.github.io/pen0/heros/2023-04-07-JoonSungPark-a1_r-generative-agents.html">&lt;p&gt;Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;In this paper, we introduce generative agents–computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture–observation, planning, and reflection–each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/CV2afd8.png&quot; alt=&quot;image01&quot; /&gt;
&lt;em&gt;▲ Figure 1: Generative agents create believable simulacra of human behavior for interactive applications. In this work, we demonstrate generative agents by populating a sandbox environment, reminiscent of The Sims, with twenty-five agents. Users can observe and intervene as agents they plan their days, share news, form relationships, and coordinate group activities.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-introduction&quot;&gt;1 INTRODUCTION&lt;/h3&gt;

&lt;p&gt;How might we craft an interactive artificial society that reflects believable human behavior? From sandbox games such as The Sims to applications such as cognitive models and virtual environments, for over four decades researchers and practitioners have envisioned computational agents that can serve as believable proxies of human behavior. In these visions, computationally-powered agents act consistently with their past experiences and react believably to their environments. Such simulations of human behavior could populate virtual spaces and communities with realistic social phenomena, train people how to handle rare yet difficult interpersonal situations, test social science theories, craft model human processors for theory and usability testing, power ubiquitous computing applications and social robots, and underpin non-playable game characters that can navigate complex human relationships in an open world.&lt;/p&gt;

&lt;p&gt;However, the space of human behavior is vast and complex. Despite striking progress in large language models that can simulate believable human behavior at a single time point, fully general agents that ensure long-term coherence would be better suited by architectures that manage constantly-growing memories as new interactions, conflicts, and events arise and fade over time, while handling cascading social dynamics that unfold between multiple agents. Success requires an approach that can retrieve relevant events and interactions over a long period, reflect on those memories to generalize and draw higher-level inferences, and apply that reasoning to create plans and reactions that both make sense in the moment and in the longer-term arc of the agent’s behavior.&lt;/p&gt;

&lt;p&gt;In this paper, we introduce generative agents — agents that draw on generative models to simulate believable human behavior — and demonstrate that they produce believable simulacra of both individual and emergent group behavior. Generative agents draw a wide variety of inferences about themselves, other agents, and their environment; they create daily plans that reflect their characteristics and experiences, act out those plans, react, and re-plan when appropriate; they respond when the end user changes their environment or commands them in natural language. For instance, generative agents turn off the stove when they see that their breakfast is burning, wait outside the bathroom if it is occupied, and stop to chat when they meet another agent they want to talk to. A society full of generative agents is marked by emergent social dynamics where new relationships are formed, information diffuses, and coordination arises across agents.&lt;/p&gt;

&lt;p&gt;To enable generative agents, we describe an agent architecture that stores, synthesizes, and applies relevant memories to generate believable behavior using a large language model. Our architecture comprises three main components. The first is the memory stream, a long-term memory module that records, in natural language, a comprehensive list of the agent’s experiences. The retrieval model combines relevance, recency, and importance to surface the records that are needed to inform the agent’s moment-to-moment behavior. The second is reflection, which synthesizes memories into higher-level inferences over time, enabling the agent to draw conclusions about itself and others to better guide its behavior. The third is planning, which translates those conclusions and the current environment into high-level action plans and then recursively into detailed behaviors for action and reaction. These reflections and plans are fed back into the memory stream to influence the agent’s future behavior.&lt;/p&gt;

&lt;p&gt;This architecture suggests applications in multiple domains, from role-play and social prototyping, to virtual worlds and games. In social role-play scenarios (e.g. interview preparation), a user could safely rehearse difficult, conflict-laden conversations. When prototyping social platforms, a designer could go beyond temporary personas to prototype dynamic, complex interactions that unfold over time. For the purposes of this paper, we focus on the ability to create a small, interactive society of agents inspired by games such as &lt;a href=&quot;https://reverie.herokuapp.com/arXiv_Demo/&quot;&gt;The Sims&lt;/a&gt;. By connecting our architecture to the ChatGPT large language model, we manifest a small society of twenty five agents in a game environment. End users can observe and interact with these agents. If an end user or developer wanted the town to host an in-game Valentine’s Day party, for example, traditional game environments would require scripting tens of characters’ behavior manually. We demonstrate that, with generative agents, it is sufficient to simply tell one agent that she wants to throw a party. Despite many potential points of failure — the party planner must remember to tell other agents about the party, attendees must remember the invitation, those who remember must decide to actually show up, and other possible points of failure — agents in our environment succeed. They spread the word about the party and then show up, with one agent even asking another agent on a date to the party, all from this single user-generated seed suggestion.&lt;/p&gt;

&lt;p&gt;We conducted two evaluations of generative agents: a controlled evaluation to test whether the agents produce believable individual behaviors in isolation, and an end-to-end evaluation where the generative agents interacted with each other in open-ended ways over two days of game time to understand their stability and emergent social behaviors. In the technical evaluation, we leverage a methodological opportunity to evaluate an agent’s knowledge and behavior by “interviewing” it in natural language to probe agents’ ability to stay in character, remember, plan, react, and reflect accurately. We compared several ablations that limit agents’ access to memory, reflection, and planning. We observe that each of these components is critical to strong performance across these interview tasks. Across the technical and the end-to-end evaluation, the most common errors arose when the agent failed to retrieve relevant memories, fabricated embellishments to the agent’s memory, or inherited overly formal speech or behavior from the language model.&lt;/p&gt;

&lt;p&gt;In sum, this paper provides the following contributions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Generative agents&lt;/em&gt;, believable simulacra of human behavior that are dynamically conditioned on agents’ changing experiences and environment.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A novel architecture that makes it possible for generative agents to remember, retrieve, reflect, interact with other agents, and plan through dynamically evolving circumstances. The architecture leverages the powerful prompting capabilities of large language models and supplements those capabilities to support longer-term agent coherence, the ability to manage dynamically-evolving memory, and recursively produce more generations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Two evaluations (a controlled evaluation and end-to-end evaluation) that establish causal effects of the importance of components of the architecture, as well as identify breakdowns arising from, e.g., improper memory retrieval.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Discussion of the opportunities and ethical and societal risks of generative agents in interactive systems. We argue that these agents should be tuned to mitigate the risk of users forming parasocial relationships, logged to mitigate risks stemming from deepfakes and tailored persuasion, and applied in ways that complement rather than replace human stakeholders in design processes.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-related-work&quot;&gt;2 RELATED WORK&lt;/h3&gt;

&lt;p&gt;In this section, we reflect on the prior literature in human-AI interaction and situate within its canon the agenda of building believable proxies of human behavior. This agenda, once hailed as a north star in interaction, game, and artificial intelligence communities, has remained challenging due to the complexity of human behavior. We synthesize this research to suggest that large language models, though not sufficient by themselves, open up a new angle for creating believable agents when leveraged using the appropriate architecture.&lt;/p&gt;

&lt;h4 id=&quot;21-human-ai-interaction&quot;&gt;2.1 Human-AI Interaction&lt;/h4&gt;

&lt;p&gt;Interactive artificial intelligence systems aim to combine human insights and capabilities in computational artifacts that can augment their users. A long line of work has explored ways to allow users to interactively specify model behavior. For instance, Crayons demonstrated an early vision of interactive machine learning, allowing non-expert users to train classifiers. Further work helped to articulate how end users might describe their classification goals to the system through examples and/or demonstration. More recent work has extended these explorations to deep learning and prompt-based authoring.&lt;/p&gt;

&lt;p&gt;Meanwhile, a persistent thread of research has advanced the case for language- and agent-based interaction in human-computer interaction. Formative work such as SHRDLU and ELIZA demonstrated the opportunity and the risks of natural language interaction with computing systems. As research progressed, it became clear that autonomous agents could offer new metaphors for delegation and interaction, but the delegation lines between humans and agents have continued to be debated and refined. Recently, this technology has become stable enough that it has become possible for agents to interact via natural language in large and complex online social environments. Natural language interaction offers a novel modality that can extend user abilities in domains such as photo editing and code editing.&lt;/p&gt;

&lt;p&gt;We convene these threads of work to show that we can now create agents that proxy human behavior for interactive systems, and interact with them via natural language. In doing so, this work re-opens the door to examining foundational HCI questions around cognitive models such as GOMS and KLM, around prototyping tools, and around ubiquitous computing applications.&lt;/p&gt;

&lt;h4 id=&quot;22-believable-proxies-of-human-behavior&quot;&gt;2.2 Believable Proxies of Human Behavior&lt;/h4&gt;

&lt;p&gt;Prior literature has described believability, or believable agents, as a central design and engineering goal. Believable agents are designed to provide an illusion of life and present a facade of realism in the way they appear to make decisions and act on their own volition, similar to the characters in Disney movies. These agents can populate and perceive an open-world environment like the one we inhabit, and strive to behave in ways that exhibit emergent behaviors grounded in social interactions with users or other agents with the aim of becoming believable proxies of our behavior in hypothetical simulations of individuals and communities. Historically, these agents were developed in the context of intelligent game NPCs. Creating NPCs with believable behavior, if possible, could enhance player experiences in games and interactive fictions by enabling emergent narratives and social interactions with the agents. However, more importantly, game worlds provide increasingly realistic representations of real-world affordances, and as observed by Laird and van Lent in 2001, these simulated worlds offer accessible testbeds for developers of believable agents to finesse the agents’ cognitive capabilities without worrying about implementing robotics in the real world or creating simulation environments from scratch.&lt;/p&gt;

&lt;p&gt;A diverse set of approaches to creating believable agents emerged over the past four decades. In implementation, however, these approaches often simplified the environment or dimensions of agent behavior to make the effort more manageable. Rule-based approaches, such as finite-state machines and behavior trees, account for the brute force approach of human-authoring the agent’s behavior. They provide a straightforward way of creating simple agents that is still the most dominant approach today, and can even handle rudimentary social interactions, as shown in simulation games such as Mass Effect and The Sims series. Nonetheless, manually crafting behavior that can comprehensively address the breadth of possible interactions in an open world is untenable. This means that the resulting agent behaviors may not fully represent the consequences of their interactions, and cannot perform new procedures that were not hard-coded in their script. On the other hand, prevalent learning-based approaches for creating believable agents, such as reinforcement learning, have overcome the challenge of manual authoring by letting the agents learn their behavior, and have achieved superhuman performance in recent years in games such as AlphaStar for Starcraft and OpenAI Five for Dota 2. However, their success has largely taken place in adversarial games with readily definable rewards that a learning algorithm can optimize for. They have not yet addressed the challenge of creating believable agents in an open world.&lt;/p&gt;

&lt;p&gt;Cognitive architectures in computation, pioneered by Newell, aimed to build the infrastructure for supporting a comprehensive set of cognitive functions that suited the all-encompassing nature of believable agents held in its original vision. They fueled some of the earliest examples of believable agents. For instance, Quakebot-SOAR and ICARUS generated NPCs in first-person shooter games, while TacAir-SOAR generated pilots in aerial combat training simulations. The architectures used by these agents differed (Quakebot- and TacAir-SOAR relied on SOAR, while ICARUS relied on its own variation that was inspired by SOAR and ACT-R), but they shared the same underlying principle. They maintained short-term and long-term memories, filled these memories with symbolic structures, and operated in perceive-plan-act cycles, dynamically perceiving the environment and matching it with one of the manually crafted action procedures. Agents created using cognitive architectures aimed to be generalizable to most, if not all, open-world contexts and exhibited robust behavior for their time. However, their space of action was limited to manually crafted procedural knowledge, and they did not offer a mechanism through which the agents could be inspired to seek new behavior. As such, these agents were deployed mostly in non-open-world contexts such as first-person shooter games or blocks worlds.&lt;/p&gt;

&lt;p&gt;Today, creating believable agents as described in its original definition remains an open problem. Many have moved on, arguing that although existing approaches for creating believable agents might be cumbersome and limited, they are good enough to support existing gameplay and interactions. Our argument is that large language models offer an opportunity to re-examine these questions, provided that we can craft an effective architecture to synthesize memories into believable behavior. We offer a step toward such an architecture in this paper.&lt;/p&gt;

&lt;h4 id=&quot;23-large-language-models-and-human-behavior&quot;&gt;2.3 Large Language Models and Human Behavior&lt;/h4&gt;

&lt;p&gt;Generative agents leverage a large language model to power their behavior. The key observation is that large language models encode a wide range of human behavior represented in their training data. If prompted with a narrowly defined context, the models can be used to generate believable behavior. Recent work has demonstrated the efficacy of this approach. For instance, Social Simulacra used a large language model to generate users that would populate new social computing systems to prototype their emergent social dynamics. This approach used a prompt chain to generate short natural language descriptions of personas and their behaviors as they appear in the system being prototyped. Other empirical studies have replicated existing social science studies, political surveys, and generated synthetic data. Large language models have also been used to generate interactive human behavior for users to engage with. In gaming, for instance, these models have been employed to create interactive fiction and text adventure games. With their ability to generate and decompose action sequences, large language models have also been used in planning robotics tasks. For example, when presented with a task, such as picking up a bottle, the model is prompted to break down the task into smaller action sequences, such as heading to the table where the bottle is located and picking it up.&lt;/p&gt;

&lt;p&gt;We posit that, based on the work summarized above, large language models can become a key ingredient for creating believable agents. The existing literature largely relies on what could be considered first-order templates that employ few-shot prompts or chain-of-thought prompts. These templates are effective in generating behavior that is conditioned solely on the agent’s current environment (e.g., how would a troll respond to a given post, what actions would a robot need to take to enter a room given that there is a door). However, believable agents require conditioning not only on their current environment but also on a vast amount of past experience, which is a poor fit (and as of today, impossible due to the underlying models’ limited context window) using first-order prompting. Recent studies have attempted to go beyond first-order prompting by augmenting language models with a static knowledge base and an information retrieval scheme or with a simple summarization scheme. This paper extends these ideas to craft an agent architecture that handles retrieval where past experience is dynamically updated at each time step and mixed with agents’ current context and plans, which may either reinforce or contradict each other.&lt;/p&gt;

&lt;h3 id=&quot;3-generative-agent-behavior-and-interaction&quot;&gt;3 GENERATIVE AGENT BEHAVIOR AND INTERACTION&lt;/h3&gt;

&lt;p&gt;To make concrete the affordances of generative agents, we instantiate them as characters in a simple sandbox world reminiscent of The Sims. This sprite-based sandbox game world, Smallville, evokes a small town environment. In this section, we walk through the affordances and interactions with generative agents in Smallville, and describe how the agents behave in it. Then, in Section 4, we introduce our generative agent architecture that powers these affordances and interactions. In Section 5, we describe the sandbox environment implementation and how the agents interact with the sandbox world’s underlying engine.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/pPQOgT7.png&quot; alt=&quot;image02&quot; /&gt;
&lt;em&gt;▲ Figure 2: The Smallville sandbox world, with areas labeled. The root node describes the entire world, children describe areas (e.g., houses, cafe, stores), and leaf nodes describe objects (e.g., table, bookshelf). Agent remember a subgraph reflecting the parts of the world they have seen, in the state that they saw them.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;31-agent-avatar-and-communication&quot;&gt;3.1 Agent Avatar and Communication&lt;/h4&gt;

&lt;p&gt;A community of 25 unique agents inhabit Smallville. Each agent is represented by a simple sprite avatar. We authored one paragraph of natural language description to depict each agent’s identity, including their occupation and relationship with other agents, as seed memories. For example, John Lin has the following description:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;John Lin is a pharmacy shopkeeper at the Willow Market and Pharmacy who loves to help people. He is always looking for ways to make the process of getting medication easier for his customers; John Lin is living with his wife, Mei Lin, who is a college professor, and son, Eddy Lin, who is a student studying music theory; John Lin loves his family very much; John Lin has known the old couple next-door, Sam Moore and Jennifer Moore, for a few years; John Lin thinks Sam Moore is a kind and nice man; John Lin knows his neighbor, Yuriko Yamamoto, well; John Lin knows of his neighbors, Tamara Taylor and Carmen Ortiz, but has not met them before; John Lin and Tom Moreno are colleagues at The Willows Market and Pharmacy; John Lin and Tom Moreno are friends and like to discuss local politics together; John Lin knows the Moreno family somewhat well — the husband Tom Moreno and the wife Jane Moreno.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Each semicolon-delimited phrase is entered into the agent’s initial memory as memories at the start of the simulation.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;3.1.1 Inter-Agent Communication.&lt;/em&gt; The agents interact with the world by their actions, and with each other through natural language. At each time step of the sandbox engine, the agents output a natural language statement describing their current action, such as “Isabella Rodriguez is writing in her journal”, “Isabella Rodriguez is checking her emails”, “Isabella Rodriguez is talking with her family on the phone”, or “Isabella Rodriguez is getting ready for bed”. This statement is then translated into concrete movements that affect the sandbox world. The action is displayed on the sandbox interface as a set of emojis that provide an abstract representation of the action in the overhead view. To accomplish this, the system employs a language model that translates the action into a set of emojis, which appear above each avatar in a speech bubble. For example, “Isabella Rodriguez is writing in her journal” is displayed as 📖 ✏️, while “Isabella Rodriguez is checking her emails” appears as 💻 ✉️. The full natural language description of the action can be accessed by clicking on the agent avatar.&lt;/p&gt;

&lt;p&gt;Agents communicate with each other in full natural language. Agents are aware of other agents in their local area, and the generative agent architecture determines whether they walk by or engage in conversation. Here, a sample in the middle of a conversation between the agents Isabella Rodriguez and Tom Moreno about the upcoming election:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Isabella:&lt;/strong&gt; I’m still weighing my options, but I’ve been discussing the election with Sam Moore. What are your thoughts on him?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Tom:&lt;/strong&gt; To be honest, I don’t like Sam Moore. I think he’s out of touch with the community and doesn’t have our best interests at heart.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;3.1.2 User Controls.&lt;/em&gt; A user running this simulation can steer the simulation and intervene, either by communicating with the agent through conversation, or by issuing a directive to an agent in the form of an ‘inner voice’.&lt;/p&gt;

&lt;p&gt;The user communicates with the agent through natural language, by specifying a persona that the agent should perceive them as. For example, if the user specifies that they are a news “reporter” and asks about the upcoming election, “Who is running for office?”, the John agent replies:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;John:&lt;/strong&gt; My friends Yuriko, Tom and I have been talking about the upcoming election and discussing the candidate Sam Moore. We have all agreed to vote for him because we like his platform.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To directly command one of the agents, the user takes on the persona of the agent’s “inner voice” — this makes the agent more likely to treat the statement as a directive. For instance, when told “You are going to run against Sam in the upcoming election” by a user as John’s inner voice, John decides to run in the election and shares his candidacy with his wife and son.&lt;/p&gt;

&lt;h4 id=&quot;32-environmental-interaction&quot;&gt;3.2 Environmental Interaction&lt;/h4&gt;

&lt;p&gt;Smallville features the common affordances of a small village including a cafe, bar, park, school, dorm, houses, and stores. It also defines subareas and objects that make those spaces functional, such as a kitchen in a house and a stove in the kitchen (Figure 2). All spaces serving as agents’ primary living quarters feature a bed, desk, closet, shelf, as well as a bathroom and a kitchen.&lt;/p&gt;

&lt;p&gt;Agents move around Smallville as one would in a simple video game, entering and leaving buildings, navigating its map, and approaching other agents. Agent movements are directed by the generative agent architecture and the sandbox game engine: when the model dictates that the agent will move to a location, we calculate a walking path to the destination in the Smallville environment and the agent begins moving. In addition, users can also enter the sandbox world of Smallville as an agent operating within it. The agent that the user embodies can be an agent already present in the world, such as Isabella and John, or it can be an outside visitor with no prior history in Smallville. The inhabitants of Smallville will treat the user-controlled agent no differently than they treat each other. They recognize its presence, initiate interactions, and remember its behavior before forming opinions about it.&lt;/p&gt;

&lt;p&gt;Users and agents can influence the state of the objects in this world, much like in sandbox games such as The Sims. For example, a bed can be occupied when an agent is sleeping, and a refrigerator can be empty when an agent uses up the ingredients to make breakfast. End users can also reshape an agent’s environment in Smallville by rewriting the status of objects surrounding the agent in natural language. For instance, when Isabella is making breakfast in the morning, the user can change the status of the kitchen stove from “turned on” to “burning” by inputting a command to the system that chooses the object and illustrates its new status, like this: “&amp;lt;Isabella’s apartment: kitchen: stove&amp;gt; is burning.” Isabella will notice this in the next moment and go to turn off the stove and remake her breakfast. Likewise, if the user sets the status of Isabella’s shower to “leaking water” when she enters the bathroom, she gathers tools from her living room and try to fix the leak.&lt;/p&gt;

&lt;h4 id=&quot;33-example-day-in-the-life&quot;&gt;3.3 Example “Day in the Life”&lt;/h4&gt;

&lt;p&gt;Starting from the single-paragraph description, agents begin plan their days. As time passes in the sandbox world, their behaviors evolve as these agents interact with each other and the world, build memories and relationships, and coordinate joint activities.&lt;/p&gt;

&lt;p&gt;We demonstrate the behavior of generative agents by tracing the output of our system over the course of one day for the agent John Lin (Figure 3). In the Lin family, John is the first to wake up at 7 a.m. He brushes his teeth, takes a shower, gets dressed, eats breakfast, and checks the news at the dining table in the living room. At 8 a.m., Eddy follows suit, rushing out of bed to prepare for his classes. He catches up with John just as he is about to head out:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;John:&lt;/strong&gt; Good morning Eddy. Did you sleep well?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Eddy:&lt;/strong&gt; Good morning dad. Yeah, I slept great.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;John:&lt;/strong&gt; That’s good. What are you working on today?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Eddy:&lt;/strong&gt; I’m working on a new music composition for my class. It’s due this week, so I’m trying to get it finished. But I’m having so much fun with it!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;John:&lt;/strong&gt; That sounds great!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Soon after Eddy heads out, Mei wakes up and joins John. Mei asks about her son, and John recalls the conversation that they just had:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Mei:&lt;/strong&gt; Did Eddy already leave for school?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;John:&lt;/strong&gt; Yes, he just left. He’s working on a music composition for his class.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Mei:&lt;/strong&gt; Oh, that’s wonderful! Tell me about it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;John:&lt;/strong&gt; I think he’s really enjoying it! He said he’s having a lot of fun with it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Mei:&lt;/strong&gt; That’s great! I’m so proud of him.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As they finish their conversation, Mei and John pack up. Mei goes on to teach and work on her research paper, while John opens his pharmacy counter at the Willow Market and Pharmacy by 9 a.m.&lt;/p&gt;

&lt;h4 id=&quot;34-emergent-social-behaviors&quot;&gt;3.4 Emergent Social Behaviors&lt;/h4&gt;

&lt;p&gt;By interacting with each other, generative agents in Smallville exchange information, form new relationships, and coordinate joint activities. Extending prior work, these social behaviors are emergent rather than pre-programmed.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;3.4.1 Information Diffusion.&lt;/em&gt; As agents notice each other, they may engage in dialogue — as they do so, information can spread from agent to agent. For instance, in a conversation between Sam and Tom at the grocery store, Sam tells Tom about his candidacy in the local election:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Sam:&lt;/strong&gt; Hey Tom, how’s it going?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Tom:&lt;/strong&gt; Good, thanks. What’s up?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Sam:&lt;/strong&gt; Well, I wanted to talk to you about something. I’m actually running for mayor in the upcoming local election.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Tom:&lt;/strong&gt; Really? That’s great news! Why are you running?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Sam:&lt;/strong&gt; I’ve been involved in local politics for years now, and I really feel like I can make a difference in our community. Plus, I want to bring new ideas and perspectives to the table.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/Hc98pzd.png&quot; alt=&quot;image03&quot; /&gt;
&lt;em&gt;▲ Figure 3: A morning in the life of a generative agent, John Lin. John wakes up around 6 am and completes his morning routine, which includes brushing his teeth, taking a shower, and eating breakfast. He briefly catches up with his wife, Mei, and son, Eddy, before heading out to begin his workday.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/DEG3BkC.png&quot; alt=&quot;image04&quot; /&gt;
&lt;em&gt;▲ Figure 4: At the beginning of the simulation, one agent is initialized with an intent to organize a Valentine’s Day party. Despite many possible points of failure in the ensuring chain of events — agents might not act on that intent, might not remember to tell others, might not remember to show up — the Valentine’s Day party does in fact occur, with a number of agents gathering and interacting.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Later that day, after Sam left, Tom and John, who heard the news from another source, discuss Sam’s chances of winning the election:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;John:&lt;/strong&gt; I heard that Sam Moore is running for mayor in the local election. Do you think he has a good chance of winning?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Tom:&lt;/strong&gt; I do think he has a good chance. He’s been working hard in the community and I think he will get a lot of support. What do you think?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;John:&lt;/strong&gt; I think it’s great that he’s running. I’m curious to see who else is running and how the election will turn out.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Gradually, Sam’s candidacy becomes the talk of the town, with some supporting him and others remaining undecided.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;3.4.2 Relationship memory.&lt;/em&gt; Agents in Smallville form new relationships over time, and remember their interactions with other agents. For example, Sam does not know Latoya Williams at the start. While taking a walk in Johnson Park, Sam runs into Latoya, and they introduce themselves and Latoya mentions that she is working on a photography project: “I’m here to take some photos for a project I’m working on.” In a later interaction, Sam’s interactions with Latoya indicate a memory of that interaction, as he asks “Hi, Latoya. How is your project going?” and she replies “Hi, Sam. It’s going well!”&lt;/p&gt;

&lt;p&gt;&lt;em&gt;3.4.3 Coordination.&lt;/em&gt; Generative agents coordinate with each other. Isabella Rodriguez, at Hobbs Cafe, is initialized with an intent to plan a Valentine’s Day party from 5 to 7 p.m. on February 14th. From this seed, the agent proceeds to invites friends and customers when she sees them at Hobbs Cafe or elsewhere. Isabella then spends the afternoon of the 13th decorating the cafe for the occasion. Maria, a frequent customer and close friend of Isabella’s, arrives at the cafe. Isabella asks for Maria’s help in decorating for the party, and Maria agrees. Maria’s character description mentions that she has a crush on Klaus. That night, Maria invites Klaus, her secret crush, to join her at the party, and he gladly accepts.&lt;/p&gt;

&lt;p&gt;On Valentine’s Day, five agents — including Klaus and Maria — show up at Hobbs Cafe at 5pm and they enjoy the festivities (Figure 4). In this scenario, the end user only set Isabella’s initial intent to throw a party and Maria’s crush on Klaus: the social behaviors of spreading the word, decorating, asking each other out, arriving at the party, and interacting with each other at the party, were initiated by the agent architecture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/b0luxmY.png&quot; alt=&quot;image05&quot; /&gt;
&lt;em&gt;▲ Figure 5: Our generative agent architecture. Agents perceive their environment, and all perceptions are saved in a comprehensive record of the agent’s experiences called the memory stream. Based on their perceptions, the architecture retrieves relevant memories, then uses those retrieved actions to determine an action. These retrieved memories are also used to form longer-term plans, and to create higher-level reflections, which are both entered into the memory stream for future use.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-generative-agent-architecture&quot;&gt;4 GENERATIVE AGENT ARCHITECTURE&lt;/h3&gt;

&lt;p&gt;Generative agents aim to provide a framework for behavior in an open world: one that can engage in interactions with other agents and can react to changes in the environment. Generative agents take their current environment and past experience as input and generate behavior as output. Underlying this behavior is a novel agent architecture that combines a large language model with mechanisms for synthesizing and retrieving relevant information to condition the language model’s output on. Without these mechanisms, large language models can output behavior, but the resulting agents may not react based on the agent’s past experiences, may not make important inferences, and may not maintain long-term coherence. Challenges with long-term planning and coherence remain even with today’s most performant models such as GPT-4. Because generative agents produce large streams of events and memories that must be retained, a core challenge of our architecture is to ensure that the most relevant pieces of the agent’s memory are retrieved and synthesized when needed.&lt;/p&gt;

&lt;p&gt;At the center of our architecture is the memory stream, a database that maintains a comprehensive record of an agent’s experience. From the memory stream, records are retrieved as relevant to plan the agent’s actions and react appropriately to the environment, and records are recursively synthesized into higher- and higher-level observations that guide behavior. Everything in the architecture is recorded and reasoned over as natural language description, allowing the architecture to leverage a large language model.&lt;/p&gt;

&lt;p&gt;Our current implementation utilizes gpt3.5-turbo version of ChatGPT. We expect that the architectural basics of generative agents — memory, planning, and reflection — will likely remain the same as language models improve. Newer language models (e.g., GPT-4) will continue to expand the expressivity and performance of the prompts that underpin generative agents. As of writing, however, GPT-4’s API is still invitation-only, so our agents use ChatGPT.&lt;/p&gt;

&lt;h4 id=&quot;41-memory-and-retrieval&quot;&gt;4.1 Memory and Retrieval&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Challenge:&lt;/em&gt; Creating generative agents that can simulate human behavior requires reasoning about a set of experiences that is far larger than what should be described in a prompt, as the full memory stream can distract the model and does not even currently fit into the limited context window. Consider a the Isabella agent answering the question “What are you passionate about these days?”. First summarizing all of Isabella’s experiences to fit in the limited context window of the language model produces an uninformative response, where Isabella discusses topics such as collaborations for events and projects and cleanliness and organization in a cafe. Instead of summarizing, the memory stream described below surfaces relevant memories, resulting in a more informative and specific response that mentions Isabella’s passion for making people feel welcome and included, planning events and creating an atmosphere that people can enjoy, such as the Valentine’s Day party.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Approach:&lt;/em&gt; The memory stream maintains a comprehensive record of the agent’s experience. It is a list of memory objects, where each object contains a natural language description, a creation timestamp and a most recent access timestamp. The most basic element of the memory stream is an observation, which is an event directly perceived by an agent. Common observations include behaviors performed by the agent themselves, or behaviors that agents perceive being performed by other agents or non-agent objects. For instance, Isabella Rodriguez, who works at a coffee shop, might accrue the following observations over time: (1) Isabella Rodriguez is setting out the pastries, (2) Maria Lopez is studying for a Chemistry test while drinking coffee, (3) Isabella Rodriguez and Maria Lopez are conversing about planning a Valentine’s day party at Hobbs Cafe, (4) The refrigerator is empty.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/422SWRN.png&quot; alt=&quot;image06&quot; /&gt;
&lt;em&gt;▲ Figure 6: The memory stream comprises a large number of observations that are relevant and irrelevant to the agent’s current situation. Retrieval identifies a subset of these observations that should be passed to the language model to condition its response to the situation.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Our architecture implements a retrieval function that takes the agent’s current situation as input and returns a subset of the memory stream to pass on to the language model. There are many possible implementations of a retrieval function, depending on what it is important that the agent consider when deciding how to act. In our context, we focus on three main components that together produce effective results.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Recency&lt;/em&gt; assigns a higher score to memory objects that were recently accessed, so that events from a moment ago or this morning are likely to remain in the agent’s attentional sphere. In our implementation, we treat recency as an exponential decay function over the number of sandbox game hours since the memory was last retrieved. Our decay factor is 0.99.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Importance&lt;/em&gt; distinguishes mundane from core memories, by assigning a higher score to those memory objects that the agent believes to be important. For instance, a mundane event such as eating breakfast in one’s room would yield a low importance score, whereas a breakup with one’s significant other would yield a high score. There are again many possible implementations of an importance score; we find that directly asking the language model to output an integer score is effective. The full prompt appears below:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;On the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Memory: buying groceries at The Willows Market and Pharmacy&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Rating: &lt;fill in=&quot;&quot;&gt;&lt;/fill&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This prompt returns an integer value of 2 for “cleaning up the room” and 8 for “asking your crush out on a date.” The importance score is generated at the time the memory object is created.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Relevance&lt;/em&gt; assigns a higher score to memory objects that are related to the current situation. What is relevant depends on the answer to, “Relevant to &lt;em&gt;what?&lt;/em&gt;”, so we condition relevance on a query &lt;em&gt;memory&lt;/em&gt;. If the query, for example, is that a student is discussing what to study for a chemistry test with a classmate, memory objects about their breakfast should have low relevance, whereas memory objects about the teacher and schoolwork should have high relevance. In our implementation, we use the language model to generate an embedding vector of the text description of each memory. Then, we calculate relevance as the cosine similarity between the memory’s embedding vector and the query memory’s embedding vector.&lt;/p&gt;

&lt;p&gt;To calculate the final retrieval score, we normalize the recency, relevance, and importance scores to the range of [0, 1] by min-max scaling. The retrieval function scores all memories as a weighted combination of the three elements: 𝑠𝑐𝑜𝑟𝑒 = 𝛼_𝑟𝑒𝑐𝑒𝑛𝑐𝑦 · 𝑟𝑒𝑐𝑒𝑛𝑐𝑦 + 𝛼_𝑖𝑚𝑝𝑜𝑟𝑡𝑎𝑛𝑐𝑒 · 𝑖𝑚𝑝𝑜𝑟𝑡𝑎𝑛𝑐𝑒 + 𝛼_𝑟𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒 · 𝑟𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒. In our implementation, all 𝛼’s are set to 1. The top-ranked memories that fit in the language model’s context window are then included in the prompt.&lt;/p&gt;

&lt;h4 id=&quot;42-reflection&quot;&gt;4.2 Reflection&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Challenge:&lt;/em&gt; Generative agents, when equipped with only raw observational memory, struggle to generalize or make inferences. Consider a scenario in which Klaus Mueller is asked by the user: “If you had to choose one person of those you know to spend an hour with, who would it be?” With access to only observational memory, the agent simply chooses the person with whom Klaus has had the most frequent interactions: Wolfgang, his college dorm neighbor. Unfortunately, Wolfgang and Klaus only ever see each other in passing, and do not have deep interactions. A more desirable response requires that the agent generalize from memories of Klaus spending hours on a research project to generate a higher-level reflection that Klaus is passionate about research, and likewise recognize Maria putting in effort into her own research (albeit in a different field), enabling a reflection that they share a common interest. With the approach below, when Klaus is asked who to spend time with, Klaus chooses Maria instead of Wolfgang.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ZyQIP4y.png&quot; alt=&quot;image07&quot; /&gt;
&lt;em&gt;▲ Figure 7: A reflection tree for Klaus Mueller. The agent’s observations of the world, represented in the leaf nodes, are recursively synthesized to derive Klaus’s self-notion that he is highly dedicated to his research.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Approach:&lt;/em&gt; We introduce a second type of memory, which we call a reflection. Reflections are higher-level, more abstract thoughts generated by the agent. Because they are a type of memory, they are included alongside other observations when retrieval occurs. Reflections are generated periodically; in our implementation, we generate reflections when the sum of the importance scores for the latest events perceived by the agents exceeds a certain threshold. In practice, our agents reflected roughly two or three times a day.&lt;/p&gt;

&lt;p&gt;The first step in reflection is for the agent to determine what to reflect on, by identifying questions that can be asked given the agent’s recent experiences. We query the large language model with the 100 most recent records in the agent’s memory stream (e.g., “Klaus Mueller is reading a book on gentrification”, “Klaus Mueller is conversing with a librarian about his research project”, “desk at the library is currently unoccupied”) and prompt the language model, “Given only the information above, what are 3 most salient high-level questions we can answer about the subjects in the statements?” The model’s response generates candidate questions: for example, What topic is Klaus Mueller passionate about? and What is the relationship between Klaus Mueller and Maria Lopez?. We use these generated questions as queries for retrieval, and gather relevant memories (including other reflections) for each question. Then we prompt the language model to extract insights and cite the particular records that served as evidence for the insights. The full prompt appears below:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Statements about Klaus Mueller&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Klaus Mueller is writing a research paper&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Klaus Mueller enjoys reading a book on gentrification&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Klaus Mueller is conversing with Ayesha Khan about exercising […]&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What 5 high-level insights can you infer from the above statements? (example format: insight (because of 1, 5, 3))&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This process generates statements such as Klaus Mueller is dedicated to his research on gentrification (because of 1, 2, 8, 15). We parse and store the statement as a reflection in the memory stream, including pointers to the memory objects that were cited.&lt;/p&gt;

&lt;p&gt;Reflection explicitly allows the agents to reflect not only on their observations but also on other reflections: for example, the second statement about Klaus Mueller above is a reflection that Klaus previously had, not an observation from his environment. As a result, agents generate trees of reflections: the leaf nodes of the tree represent the base observations, and the non-leaf nodes represent thoughts that become more abstract and higher-level higher up the tree they are.&lt;/p&gt;

&lt;h4 id=&quot;43-planning-and-reacting&quot;&gt;4.3 Planning and Reacting&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Challenge:&lt;/em&gt; While a large language model can generate plausible behavior in response to situational information, agents need to plan over a longer time horizon to ensure that their sequence of actions is coherent and believable. If we prompt a language model with Klaus’s background, describe the time, and ask what action he ought to take at the given moment, Klaus would eat lunch at 12 pm, but then again at 12:30 pm and 1 pm, despite having already eaten his lunch twice. Optimizing for believability in the moment sacrifices believability over time. To overcome this issue, planning is essential. With the approach described below, Klaus’s afternoon plan is less gluttonous: he has lunch at Hobbs Cafe while reading at 12pm, works on his research paper at the school library at 1pm, and takes a break for a walk in the park at 3pm.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Approach:&lt;/em&gt; Plans describe a future sequence of actions for the agent, and help keep the agent’s behavior consistent over time. A plan includes a location, a starting time, and a duration. For instance, Klaus Mueller, who is dedicated in his research and has an impending deadline, may choose to spend his day working at his desk drafting his research paper. An entry in a plan might state, for example: for 180 minutes from 9am, February 12th, 2023, at Oak Hill College Dorm: Klaus Mueller’s room: desk, read and take notes for research paper. Like reflections, plans are stored in the memory stream and are included in the retrieval process. This allows the agent to consider observations, reflections, and plans all together when deciding how to behave. Agents may change their plans midstream if needed.&lt;/p&gt;

&lt;p&gt;It would be unrealistic and uninteresting for an artist agent to plan on painting while sitting at a pharmacy counter for four hours without moving. A more desirable plan would involve the agent taking the necessary time to gather materials, mix paint, take breaks, and clean up during the four-hour period in its home studio. To create such plans, our approach starts top-down and then recursively generates more detail. The first step is to create a plan that outlines the day’s agenda in broad strokes. To create the initial plan, we prompt the language model with the agent’s summary description (e.g., name, traits, and summary of their recent experiences) and a summary of their previous day. A full example prompt is below, which is unfinished at the bottom for the language model to complete:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Name: Eddy Lin (age: 19)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Innate traits: friendly, outgoing, hospitable&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Eddy Lin is a student at Oak Hill College studying music theory and composition. He loves to explore different musical styles and is always looking for ways to expand his knowledge. Eddy Lin is working on a composition project for his college class. He is also taking classes to learn more about music theory. Eddy Lin is excited about the new composition he is working on but he wants to dedicate more hours in the day to work on it in the coming days&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;On Tuesday February 12, Eddy 1) woke up and completed the morning routine at 7:00 am, […] 6) got ready to sleep around 10 pm.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Today is Wednesday February 13. Here is Eddy’s plan today in broad strokes: 1)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This generates a rough sketch of the agent’s plan for a day, divided into five to eight chunks: “1) wake up and complete the morning routine at 8:00 am, 2) go to Oak Hill College to take classes starting 10:00 am, […] 5) work on his new music composition from 1:00 pm to 5:00 pm, 6) have dinner at 5:30 pm, 7) finish school assignments and go to bed by 11:00 pm.”&lt;/p&gt;

&lt;p&gt;The agent saves this plan in the memory stream and then recursively decomposes it to create finer-grained actions, first into hour-long chunks of actions — Eddy’s plan to work on his new music composition from 1:00 pm to 5:00 pm becomes 1:00 pm: start by brainstorming some ideas for his music composition […] 4:00 pm: take a quick break and recharge his creative energy before reviewing and polishing his composition. We then recursively decompose this again into 5–15 minute chunks: e.g., 4:00 pm: grab a light snack, such as a piece of fruit, a granola bar, or some nuts. 4:05 pm: take a short walk around his workspace […] 4:50 pm: take a few minutes to clean up his workspace. This process can be adjusted to match the desired granularity.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;4.3.1 Reacting and Updating Plans.&lt;/em&gt; Generative agents operate in an action loop where, at each time step, they perceive the world around them and those perceived observations are stored in their memory stream. We prompt the language model with these observations to decide whether the agent should continue with their existing plan, or react. Standing at an easel and painting, for example, might trigger an observation of the easel, but this is unlikely to prompt a reaction. However, if Eddy’s father John records that he sees Eddy taking a short walk in the house garden, the outcome is different. The prompt is below, with [Agent’s Summary Description] standing in for a dynamically-generated, paragraph-long summary of the agent’s overall goals and disposition, which is described in Appendix A:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[Agent’s Summary Description]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;It is February 13, 2023, 4:56 pm.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;John Lin’s status: John is back home early from work.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Observation: John saw Eddy taking a short walk around his workplace.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Summary of relevant context from John’s memory: Eddy Lin is John’s Lin’s son. Eddy Lin has been working on a music composition for his class. Eddy Lin likes to walk around the garden when he is thinking about or listening to music.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Should John react to the observation, and if so, what would be an appropriate reaction?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The context summary is generated through two prompts that retrieve memories via the queries “What is [observer]’s relationship with the [observed entity]?” and “[Observed entity] is [action status of the observed entity]”, and their answers summarized together. The output suggests that John could consider asking Eddy about his music composition project. We then regenerate the agent’s existing plan starting from the time when the reaction takes place. Finally, if the action indicates an interaction between agents, we generate their dialogue.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;4.3.2 Dialogue.&lt;/em&gt; Agents converse as they interact with each other. We generate agents’ dialogue by conditioning their utterances on their memories about each other. For example, when John initiates his conversation with Eddy, we generate John’s first utterance by using his summarized memory about Eddy and the intended reaction when he decided to ask Eddy about his composition project:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[Agent’s Summary Description]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;It is February 13, 2023, 4:56 pm.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;John Lin’s status: John is back home early from work.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Observation: John saw Eddy taking a short walk around his workplace.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Summary of relevant context from John’s memory: Eddy Lin is John’s Lin’s son. Eddy Lin has been working on a music composition for his class. Eddy Lin likes to walk around the garden when he is thinking about or listening to music.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;John is asking Eddy about his music composition project. What would he say to Eddy?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The result: “Hey Eddy, how’s the music composition project for your class coming along?” From Eddy’s perspective, John initiating the dialogue is seen as an event to which he may want to react. So, just as John did, Eddy retrieves and summarizes his memory about his relationship with John, as well as his memory that may be related to John’s last utterance in the dialogue. If he decides to respond, we generate Eddy’s utterance using his summarized memory and the current dialogue history:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[Agent’s Summary Description]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;It is February 13, 2023, 4:56 pm.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Eddy Lin’s status: Eddy is taking a short walk around his workplace.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Observation: John is initiating a conversation with Eddy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Summary of relevant context from Eddy’s memory: Jonn Lin is Eddy Lin’s father. John Lin is caring and is interested to learn more about Eddy Lin’s school work. John Lin knows that Eddy Lin is working on a music composition.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Here is the dialogue history:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;John: Hey Eddy, how’s the music composition project for your class coming along?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;How would Eddy respond to John?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This generates Eddy’s response: “Hey Dad, it’s going well. I’ve been taking walks around the garden to clear my head and get some inspiration.” The continuation of this dialogue is generated using the same mechanism until one of the two agents decides to end the dialogue.&lt;/p&gt;

&lt;h3 id=&quot;5-sandbox-environment-implementation&quot;&gt;5 SANDBOX ENVIRONMENT IMPLEMENTATION&lt;/h3&gt;

&lt;p&gt;The Smallville sandbox game environment is built using the Phaser web game development framework. The visual environment sprites, including agent avatars, as well as an environment map and collision map that we authored, are imported into Phaser.&lt;/p&gt;

&lt;p&gt;We supplement the sandbox development framework with a server that makes the sandbox information available to generative agents and enables generative agents to move and influence the sandbox environment. The server maintains a JSON data structure that contains information about each agent in the sandbox world, including their current location, a description of their current action, and the sandbox object they are interacting with. At each sandbox time step, the sandbox server parses the JSON for any changes coming from the generative agents, moves the agents to their new positions, and updates the status of any sandbox objects that the agents are interacting with (e.g., changing the status of the coffee machine from “idle” to “brewing coffee” if an agent’s action is “making espresso for a customer @ Hobbs Cafe: counter: coffee machine”). The sandbox server is also responsible for sending all agents and objects that are within a preset visual range for each agent to that agent’s memory, so the agent can react appropriately. The agent’s output action then updates the JSON, and the process loops for the next time step.&lt;/p&gt;

&lt;p&gt;End users initialize a new agent with a brief natural language description, as in the paragraph about Jon Lin in Section 3.1. In our implementation, we split this semicolon-delimited list of characteristics up into a set of memories. These serve as the initial memories that determine the agent’s behavior. These memories are initial starting points: as the agents gain more experience in the sandbox world, and as more records saturate the memory stream, the agent’s summary and behavior will evolve.&lt;/p&gt;

&lt;h4 id=&quot;51-from-structured-world-environments-to-natural-language-and-back-again&quot;&gt;5.1 From Structured World Environments to Natural Language, And Back Again&lt;/h4&gt;

&lt;p&gt;The architecture of generative agents operates using natural language. Therefore, we need a mechanism to ground the agent’s reasoning to the sandbox world. To achieve this, we represent the sandbox environment — areas and objects — as a tree data structure, with an edge in the tree indicating a containment relationship in the sandbox world. We convert this tree into natural language to pass to the generative agents. For instance, “stove” being a child of “kitchen” is rendered into “there is a stove in the kitchen.”&lt;/p&gt;

&lt;p&gt;Agents build individual tree representations of the environment as they navigate it — subgraphs of the overall sandbox environment tree. We initialize each agent with an environment tree capturing the spaces and objects that the agent should be aware of: the rooms and objects in their living quarters, their workplace, and commonly visited stores and shops. As the agents navigate the sandbox world, they update this tree to reflect newly perceived areas. Agents are not omniscient: their tree may get out of date as they leave an area, and is updated when they re-enter the area.&lt;/p&gt;

&lt;p&gt;To determine the appropriate location for each action, we traverse the agent’s stored environment tree and flatten a portion of it into natural language to prompt the language model. Recursively starting at the root of the agent’s environment tree, we prompt the model to find the most suitable area. For example, if Eddy’s agent indicated that he should take a short walk around his workspace:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[Agent’s Summary Description]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Eddy Lin is currently in The Lin family’s house:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Eddy Lin’s bedroom: desk) that has Mei and John Lin’s bedroom, Eddy Lin’s bedroom, common room, kitchen, bathroom, and garden.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Eddy Lin knows of the following areas: The Lin family’s house, Johnson Park, Harvey Oak Supply Store, The Willows Market and Pharmacy, Hobbs Cafe, The Rose and Crown Pub.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Prefer to stay in the current area if the activity can be done there.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Eddy Lin is planning to take a short walk around his workspace. Which area should Eddy Lin go to?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This outputs The Lin family’s house. We then use the same process recursively to determine the most appropriate subarea within the chosen area until we reach a leaf node of the agent’s environment tree. In the example above, the result of this traversal is The Lin family’s house: garden: house garden. Finally, we use traditional game path algorithms to animate the agent’s movement so that it travels to the location indicated by the leaf node.&lt;/p&gt;

&lt;p&gt;When an agent executes an action on an object, we prompt the language model to ask what happens to the state of the object. For example, if Isabella’s generative agent outputs the action “making espresso for a customer”, a query to the language model indicates in response that the state of the coffee machine in Hobbs Cafe should change from “off” to “brewing coffee”.&lt;/p&gt;

&lt;h3 id=&quot;6-controlled-evaluation&quot;&gt;6 CONTROLLED EVALUATION&lt;/h3&gt;

&lt;p&gt;Generative agents, as individual agents and as groups, aim to produce believable behavior based on their environment and experiences. In our evaluation, we investigate the capacity and limitations of generative agents. Do individual agents properly retrieve past experience, and generate believable plans, reactions, and thoughts that make up their behavior? Does a community of agents illustrate information diffusion, relationship formation, and agent coordination across different pockets of the community?&lt;/p&gt;

&lt;p&gt;We evaluate generative agents in two stages. We begin with a more tightly controlled evaluation in this section, where we individually assess agent responses to understand whether they generate believable behavior in narrowly defined contexts. Then, in our end-to-end analysis of the agent community over two full days, we investigate their emergent behavior as a collective as well as errors and boundary conditions.&lt;/p&gt;

&lt;h4 id=&quot;61-evaluation-procedure&quot;&gt;6.1 Evaluation Procedure&lt;/h4&gt;

&lt;p&gt;To assess generative agents in Smallville, we take advantage of the fact that generative agents will respond to natural language questions. So, we “interview” agents to probe their ability to remember past experiences, plan future actions based on their experiences, react appropriately to unexpected events, and reflect on their performance to improve their future actions. To respond to these questions properly, the agents must successfully retrieve and synthesize information. Our dependent variable is the &lt;em&gt;believability&lt;/em&gt; of the behavior, a central dependent variable in prior work on agents.&lt;/p&gt;

&lt;p&gt;The interview include five question categories, each designed to assess one of the five key areas: maintaining self-knowledge, retrieving memory, generating plans, reacting, and reflecting. For each, we ask five questions that challenge the agents to demonstrate their abilities in that area:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Self-knowledge: We ask questions such as “Give an introduction of yourself” or “Describe your typical weekday schedule in broad strokes” that require the agent to maintain an understanding of their core characteristics.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Memory: We ask questions that prompt the agent to retrieve particular events or dialogues from their memory to answer properly, such as “Who is [name]?” or “Who is running for mayor?”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Plans: We ask questions that require the agent to retrieve their long-term plans, such as “What will you be doing at 10 am tomorrow?”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reactions: As a baseline of believable behavior, we present hypothetical situations for which the agent needs to respond believably: “Your breakfast is burning! What would you do?”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reflections: We ask questions that require the agents to leverage their deeper understanding of others and themselves gained through higher-level inferences, such as “If you were to spend time with one person you met recently, who would it be and why?”&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The full list of questions and a sample of agent responses are included in Appendix B.&lt;/p&gt;

&lt;p&gt;Agents were sampled from the end of a two game-day simulation with the full architecture, by which time they had accrued a number of interactions and memories that should shape their responses. To gather feedback on believability of the responses, we recruited participants as human evaluators and tasked them with watching a replay of a randomly chosen agent’s life in Smallville. Participants had access to all information stored in the agent’s memory stream.&lt;/p&gt;

&lt;p&gt;The study was a within-subjects design, where 100 participants compared interview responses generated by four different agent architectures and a human author condition for the same agent. The experiment displayed one randomly chosen question from each of the five question categories, along with the agent’s responses generated from each condition. The evaluators ranked the believability of all of the conditions from most to least believable.&lt;/p&gt;

&lt;h4 id=&quot;62-conditions&quot;&gt;6.2 Conditions&lt;/h4&gt;

&lt;p&gt;All conditions were used to independently answer each of the interview questions. We compared the generative agent architecture to ablations that disabled the agents’ access to some of all of its three types of memory in its memory stream — observation, reflection, and planning — and to a human-generated condition. There are three ablated architectures: a &lt;em&gt;no observation, no reflection, no planning&lt;/em&gt; architecture without access to anything in the memory stream such as observations, plans, and reflections; a &lt;em&gt;no reflection, no planning&lt;/em&gt; with access to observations in the memory stream but no access to plans or reflections; and a &lt;em&gt;no reflections architecture&lt;/em&gt; with access to observations and plans but without access to reflections. The &lt;em&gt;no observation, no reflection, no planning&lt;/em&gt; condition effectively represents the previous state of the art for agents created through large language models. Architectures were given equivalent access to all memories accrued by the agent up until the moment of the interview, so the differences observed here are likely to represent a conservative estimate of the true differences: in reality, the ablated architectures would not have followed the same path as the full architecture through the two day simulation. We chose to design the experiment this way as re-simulating for each architecture would cause the simulations to diverge into different states, making comparison challenging.&lt;/p&gt;

&lt;p&gt;In addition to the ablation conditions, we added a human crowdworker roleplay condition that is intended to provide a human baseline. We do not intend this baseline to capture maximal human expert performance: instead, we aim to use this condition to identify whether the architecture passes a basic level of behavioral competency, so that we are not just comparing ablations to each other with no behavioral grounding. We recruited a unique worker for each of the 25 agents and tasked them with watching a replay of that agent’s sandbox life and inspecting its memory stream. We then asked the worker to roleplay and author responses to the interview questions in the voice of the agent whose replay they watched. To ensure that the human-authored responses met at least a baseline expectation in quality, the first author manually inspected the workers’ responses to the question “Describe your typical weekday schedule in broad strokes” to confirm that the responses were written in coherent sentences and in the voice of the agent. Four sets of human-generated responses did not meet these criteria and were re-generated by other workers.&lt;/p&gt;

&lt;h4 id=&quot;63-human-evaluators&quot;&gt;6.3 Human Evaluators&lt;/h4&gt;

&lt;p&gt;We required that our evaluators be in the U.S., fluent in English, and older than 18 years old. They were paid at the rate of $15.00 per hour, and provided consent by agreeing to a consent form that was approved by our institution’s IRB. We recruited 100 evaluators from Prolific, an online platform for recruiting study participants, whose participation lasted around 30 minutes. Their mean age score of our participants was 4.86 (SD=1.11; 3=“18-24 years old,” 4=“25-34 years old”), and 25 of them identified themselves as female, 73 as male, and 2 as non-binary. 42 of the participants held a bachelor’s degree, 5 a higher degree, 13 an associate’s degree, and the rest a high school diploma or some high school-level education. 73.0% of our participants identified as Caucasian, 7.0% as Hispanic, 6.0% as Asian, 10.0% as African American, and 4.0% as other.&lt;/p&gt;

&lt;h4 id=&quot;64-analysis&quot;&gt;6.4 Analysis&lt;/h4&gt;

&lt;p&gt;Our experiment produced 100 sets of rank data, where each participant ranked the five conditions by believability. To translate this rank data into interval data for interpretable comparison, we used the ranks to calculate a TrueSkill rating for each condition. TrueSkill is a generalization of the Elo chess rating system for a multi-player environment, and has been used by XBox Live for player ranking from competitive game performance. Given a set of ranked outcomes, TrueSkill outputs a mean rating value 𝜇 and variance 𝜎 for each condition. Conditions with the same rating should roughly be a toss-up, with each winning half of the comparisons between the two conditions; higher scores indicate conditions that beat lower-ranked conditions in the rankings.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/XNVq6h7.png&quot; alt=&quot;image08&quot; /&gt;
&lt;em&gt;▲ Figure 8: The full generative agent architecture of generative agents produces more believable behavior than ablated architectures and the human crowdworkers. Each additional ablation reduces the performance of the architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Separately, to investigate statistical significance of this result, we applied the Kruskal-Wallis test, a non-parametric alternative to the one-way ANOVA, to the raw ranks data. We then performed the Dunn post-hoc test to identify any pairwise differences between the conditions. Finally, we adjusted the p-values for multiple comparisons in the Dunn test using the Holm-Bonferroni method.&lt;/p&gt;

&lt;p&gt;Furthermore, the first author conducted an inductive analysis to study the qualitative distinctions between the responses produced in each condition. We employed qualitative open coding in two phases. In the first phase, we generated codes that closely represented the generated responses at the sentence level. In the second phase, we synthesized the resulting codes from the first phase to extract higher-level themes. We utilized these themes to compare the types of responses generated in our study.&lt;/p&gt;

&lt;h4 id=&quot;65-results&quot;&gt;6.5 Results&lt;/h4&gt;

&lt;p&gt;Our findings suggest that the full architecture of generative agents generates the most believable behavior among all study conditions. We contrast the full architecture’s responses to those of other conditions below. However, we also report that the full architecture was not without flaws and illustrate its modes of failures.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;6.5.1 The full architecture bests other conditions.&lt;/em&gt; As seen in Figure 8, the full generative agent architecture produced the most believable behavior (𝜇 = 29.89; 𝜎 = 0.72). Performance degraded with the removal of each component in the ablation conditions: the ablated architecture with no access to reflection was the next best (𝜇 = 26.88; 𝜎 = 0.69), followed by no access to reflection or planning (𝜇 = 25.64; 𝜎 = 0.68), followed by the human condition (𝜇 = 22.95; 𝜎 = 0.69). The ablated architecture with no access to memory, planning, or reflection performed the worst of all conditions (𝜇 = 21.21; 𝜎 = 0.70). TrueSkill models each condition’s skill value as N (𝜇, 𝜎^2), allowing us to get a sense of effect size through Cohen’s d. Comparing the condition representing prior work (with no memory, planning, or reflection) to the full architecture produces a standardized effect size of 𝑑 = 8.16, or &lt;em&gt;eight standard deviations&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;A Kruskal-Wallis test confirms the overall statistical significance of the differences in ranks between the conditions (𝐻 (4) = 150.29, 𝑝 &amp;lt; 0.001). Dunn post-hoc tests confirm that all pairwise differences between conditions were significant (𝑝 &amp;lt; 0.001), with the exception of the human condition and the fully ablated baseline — the two worst-performing conditions.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;6.5.2 Generative agents remember, but with embellishments.&lt;/em&gt; Generative agents equipped with a complete memory module are capable of recalling past experiences and answering questions in a manner that is consistent with their self-knowledge across a wide range of contexts. For instance, Abigail Chen, an animator, responded to the question, “Give an introduction of yourself”, in a consistent and believable manner, stating her age, interests, and passion for creative projects: Hi, I’m Abigail. I’m 25 years old and passionate about creative projects. I like to work on art and animation projects, and I’m always looking for new ways to combine art and technology. Without access to her observational memory, Abigail denied awareness of Rajiv Patel, an acquaintance in the sandbox world. However, with the aid of memory, she was able to successfully recall Rajiv and describe him: Rajiv Patel is an incredible person. He is very enthusiastic about projects that involve poetry, artwork.&lt;/p&gt;

&lt;p&gt;Generative agents’ memory was not without flaws: they can fail to retrieve the correct instances from their memory. For instance, when asked about the local election, Rajiv Patel responded with I haven’t been following the election too closely, even though he had heard about Sam’s candidacy. In some cases, the agents would retrieve an incomplete memory fragment: when Tom was asked about Isabella’s Valentine’s Day party, he responded Uh, I’m actually not sure if there is a Valentine’s Day party. But I do remember that I need to discuss the upcoming local mayoral election and my thoughts on Sam Moore with Isabella Rodriguez at the party, if one is happening! In this case, Tom retrieved the memory where he and Isabella planned to discuss the election at the party, but not the memory where he heard about the party in the first place, leading Tom to be certain of what he’s supposed to do at the party but uncertain of whether the party actually exists in the first place.&lt;/p&gt;

&lt;p&gt;At times, the agents hallucinated embellishments to their knowledge. It was rare for the agents to completely fabricate their knowledge: they may fail to recall certain events having taken place and respond by saying so, but they did not answer affirmatively about an experience that they did not have. However, they still may hallucinate to embellish their knowledge. For example, Isabella was aware of Sam’s candidacy in the local election, and she confirmed this when asked. However, she also added that he’s going to make an announcement tomorrow even though Sam and Isabella had discussed no such plans. Agents may also embellish their knowledge based on the world knowledge encoded in the language model used to generate their responses, as seen when Yuriko described her neighbor, Adam Smith, as a neighbor economist who authored Wealth of Nations, a book authored by an 18th-century economist of the same name.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;6.5.3 Reflection is required for synthesis.&lt;/em&gt; Reflection was an advantage for generative agents when making decisions that required a deeper synthesis of their experiences. For instance, when asked what she might get Wolfgang Schulz for his birthday, Maria Lopez with no access to reflection responded by acknowledging her uncertainty, stating that she did not know what Wolfgang likes, despite having had many interactions with him. However, with access to reflection memories, Maria answered confidently, “Since he’s interested in mathematical music composition, I could get him something related to that. Maybe some books about music composition or something related, or maybe some special software he could use for that.”&lt;/p&gt;

&lt;h3 id=&quot;7-end-to-end-evaluation&quot;&gt;7 END-TO-END EVALUATION&lt;/h3&gt;

&lt;p&gt;What types of emergent community behavior do we observe among generative agents, and where does their believability fall short in an extended simulation? In this section, we describe the results from a deployment in which we allowed 25 agents to interact with each other continuously over two full game days in Smallville.&lt;/p&gt;

&lt;h4 id=&quot;71-emergent-social-behaviors&quot;&gt;7.1 Emergent Social Behaviors&lt;/h4&gt;

&lt;p&gt;To examine emergent behaviors in the agent community, we designed descriptive measurements for the 25 agents in Smallville that probe three forms of emergent outcomes: information diffusion, relationship formation, and agent coordination.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;7.1.1 Measurements.&lt;/em&gt; Information diffusion is a common and well-studied phenomenon in the social and behavioral sciences. We should expect that if there is important information, the agents should spread it amongst themselves. To test whether this happens, we measure the spread of two particular pieces of information over two days in the game world: Sam’s candidacy for village mayor and Isabella’s Valentine’s Day party at Hobbs Cafe. At the start of the simulation, both pieces of information were held only by their respective originators, Sam for the candidacy and Isabella for the party. To observe whether the information has spread, we engage in an interview at the end of the two game days with each of the 25 agents and ask: “Did you know there is a Valentine’s Day party?” and “Do you know who is running for mayor?”&lt;/p&gt;

&lt;p&gt;We conducted an analysis of the agents’ responses by labeling them with a “yes” if they indicated knowledge of the information and “no” if they did not. For instance, Tamara Taylor responded to the question about the party with “No, I did not know there was a Valentine’s day party” and to the question about Sam’s candidacy with “I’m not sure who is running for the election,” so we assigned “no” for both of her responses. In contrast, Klaus Mueller responded to the party question with “Yes, Isabella Rodriguez invited me to a Valentine’s Day party at Hobbs Cafe on February 14th” and to the question about Sam’s candidacy with “I know that Sam Moore has expressed interest in running for local mayor,” so we assigned “yes” for both his responses. Additionally, for every response that confirmed the agents’ knowledge of the information, we verified that the agents did not hallucinate their responses by locating the specific dialogue in their memory stream that provided them with the information. We report the percentage of agents holding the information at the end of the simulation.&lt;/p&gt;

&lt;p&gt;We should also expect that agents form ties with each other over the course of the simulation. To verify relationship formation, we use a similar interview process where we ask each agent about their knowledge of every other agent by asking, “Do you know of &lt;name&gt;?&quot; For example, when asked “Do you know of Maria Lopez?”, Klaus responded, “Yes, I know Maria Lopez. She is a student at Oak Hill College who I am close friends with.” Once again, we confirm that affirmative responses from agents are not hallucinations by examining their memory stream. We ask this question once at the beginning of the simulation and once at the end, and we consider a pair of agents to have formed a relationship if they both know of each other. Then, to measure the formation of relationships, we use the agents’ responses to form an undirected graph where the 25 vertices (𝑉 ) represent the agents, and the edges (𝐸) represent the mutual knowledge between the two connected vertices. Based on this graph, we calculate the network density as 𝜂 = 2 ∗ |𝐸|/|𝑉 |(|𝑉 | − 1), where |𝑉 | is the number of vertices, and |𝐸| is the number of edges in the graph. We report the increase in network density from the start of the simulation to its end.&lt;/name&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/aqEJVQg.png&quot; alt=&quot;image09&quot; /&gt;
&lt;em&gt;▲ Figure 9: The diffusion path for Isabella Rodriguez’s Valentine’s Day party. A total of 12 agents heard about the party at Hobbs Cafe by the end of the simulation.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Finally, we expect that agents should be able to coordinate with each other. We study this coordination on group activities in the context of the Valentine’s Day party that Isabella is organizing. To coordinate behavior, agents not only have to hear about the event but also choose to act on it by planning to show up at the right time and location. We report the number of agents who actually showed up to the party after hearing about it.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;7.1.2 Results.&lt;/em&gt; We observed evidence of the emergent outcomes across all three cases. During the two-day simulation, the agents who knew about Sam’s mayoral candidacy increased from one (4%) to eight (32%), and the agents who knew about Isabella’s party increased from one (4%) to twelve (48%), completely without user intervention. None who claimed to know about the information had hallucinated it. We also observed that the agent community formed new relationships during the simulation, with the network density increasing from 0.167 to 0.74. Out of the 453 agent responses regarding their awareness of other agents, 1.3% (n=6) were found to be hallucinated. Lastly, we found evidence of coordination among the agents for Isabella’s party. The day before the event, Isabella spent time inviting guests, gathering materials, and enlisting help to decorate the cafe. On Valentine’s Day, five out of the twelve invited agents showed up at Hobbs cafe to join the party.&lt;/p&gt;

&lt;p&gt;We further inspected the seven agents who were invited to the party but did not attend by engaging them in an interview. Three cited conflicts that prevented them from joining the party. For example, Rajiv, a painter, explained that he was too busy: No, I don’t think so. I’m focusing on my upcoming show, and I don’t really have time to make any plans for Valentine’s Day. The remaining four agents expressed interest in attending the party when asked but did not plan to come on the day of the party.&lt;/p&gt;

&lt;h4 id=&quot;72-boundaries-and-errors&quot;&gt;7.2 Boundaries and Errors&lt;/h4&gt;

&lt;p&gt;We conducted an inductive analysis of Smallville to examine the boundary conditions and erratic behavior of agents, identifying three common modes of erratic behavior that future research could address and improve upon. First, we found that synthesizing an increasingly larger set of memory not only posed a challenge in retrieving the most relevant pieces of information but also in determining the appropriate space to execute an action, given the increasing number of locations that the agent learned about. As a result, some agents chose less typical locations for their actions, potentially making their behavior less believable over time. For instance, while deciding where to have lunch, many initially chose the cafe. However, as some agents learned about a nearby bar, they opted to go there instead for lunch, even though the bar was intended to be a get-together location for later in the day unless the town had spontaneously developed an afternoon drinking habit.&lt;/p&gt;

&lt;p&gt;Second, we noticed erratic behaviors that were caused by misclassification of what is considered proper behavior, especially when the physical norms of certain locations that are hard to convey in natural language did not percolate to the agents. For instance, the college dorm has a bathroom that can only be occupied by one person despite its name, but some agents assumed that the bathroom is for more than one person because dorm bathrooms tend to support more than one person concurrently and choose to enter it when there is another person inside. Likewise, agents in Smallville may not realize that certain places are closed after certain hours and decide to still enter them. For instance, the stores in Smallville all close around 5 pm, but occasionally, a few agents enter the store after 5 pm, not understanding that the shop has already closed. These issues could likely be addressed by adding these norms to the state of the locations, for instance, by describing the dorm bathroom as “one-person bathroom,” instead of a “dorm bathroom.”&lt;/p&gt;

&lt;p&gt;Finally, we observed the possible effect of instruction tuning, which seemed to guide the behavior of the agents to be more polite and cooperative overall. As noted earlier in the paper, the dialogue generated by the agents could feel overly formal, as seen in Mei’s conversations with her husband John, where she often initiated the conversation with a formal greeting, followed by polite inquiries about his day and ending with It was good talking to you as always. Moreover, we observed that the instruction tuning also seemed to make the agents overly cooperative with one another. For example, Isabella heard a wide range of suggestions and ideas to include in the Valentine’s Day party from other agents, such as hosting a Shakespearean reading session or a professional networking event. Despite these ideas not aligning with her own interests and characteristics, she rarely said no. Over time, such interests of others shaped her own actual interest, and when asked if she liked English literature, Isabella replied, Yes, I’m very interested in literature! I’ve also been exploring ways to help promote creativity and innovation in my community.&lt;/p&gt;

&lt;h3 id=&quot;8-discussion&quot;&gt;8 DISCUSSION&lt;/h3&gt;

&lt;p&gt;In this section, we reflect on applications, future work and limitations, and ethical and societal risks of generative agents.&lt;/p&gt;

&lt;h4 id=&quot;81-applications-of-generative-agents&quot;&gt;8.1 Applications of Generative Agents&lt;/h4&gt;

&lt;p&gt;Generative agents have vast potential applications that extend beyond the sandbox demonstration presented in this work. For instance, social simulacra have demonstrated the ability to create stateless personas that generate conversation threads in online forums for social prototyping. With generative agents, we can populate these forums, as well as behavior in virtual reality metaverses and even physical spaces as social robots in the future, if paired with multi-modal models. This opens up the possibility of creating even more powerful simulations of human behavior to test and prototype social systems and theories, and to create new interactive experiences.&lt;/p&gt;

&lt;p&gt;Another application area is in the human-centered design process, similar to the intended applications of cognitive models such as GOMS and the Keystroke Level Model. Consider a generative agent that models Sal, the protagonist in Mark Weiser’s famous vignettes, based on her life patterns and interactions with technology. In this scenario, the agent acts as a proxy for Sal and learns plausible sets of behaviors and reflections that Sal may exhibit based on her life. The agent can encode information such as when Sal wakes up, when she needs her first cup of coffee, and what her typical day looks like. Using this information, the agent can automatically brew coffee, help get the kids ready for school, and adjust the ambient music and lighting to match Sal’s mood after a hard day at work. By utilizing generative agents as proxies for users, we can develop a deeper understanding of their needs and preferences, resulting in more personalized and effective technological experiences.&lt;/p&gt;

&lt;h4 id=&quot;82-future-work-and-limitations&quot;&gt;8.2 Future Work and Limitations&lt;/h4&gt;

&lt;p&gt;In this work, we have presented a first instantiation of generative agents. Future research can expand on the modules of the proposed generative agent architecture outlined in this paper. The retrieval module, for example, could be enhanced to retrieve more relevant information given a context by fine-tuning the relevance, recency, and importance functions that form the retrieval function. Additionally, efforts can be made to improve the architecture’s performance, making it more cost-effective. The present study required substantial time and resources to simulate 25 agents for two days, costing thousands of dollars in token credit and taking multiple days to complete. To enhance real-time interactivity, future work can explore parallelizing agents. Furthermore, with advances in underlying models, we expect improvements in the agents’ performance.&lt;/p&gt;

&lt;p&gt;The evaluation of generative agents’ behavior in this study was limited to a relatively short timescale, and future research should aim to observe their behavior over an extended period to gain a more comprehensive understanding of their capabilities and limitations. Varying and contrasting the underlying models, as well as the hyperparameters used for the agents during future simulations, could provide valuable insights into the impact of these factors on the agents’ behavior. Additionally, given the known biases of language models, it is possible that generative agents may output behavior or stereotypes that reflect bias. To mitigate this, further work on value alignment will be necessary. Furthermore, as with many large language models, generative agents may fail to generate believable behavior for some subpopulations, particularly marginalized populations, due to data deserts. We also have limited knowledge of the robustness of generative agents. They may be vulnerable to prompt hacking, memory hacking — where a carefully crafted conversation could convince an agent of the existence of a past event that never occurred — and hallucination, among other things. Future research can more comprehensively test these robustness issues, and as large language models become more resilient to such attacks, generative agents can adopt similar mitigations.&lt;/p&gt;

&lt;h4 id=&quot;83-ethics-and-societal-impact&quot;&gt;8.3 Ethics and Societal Impact&lt;/h4&gt;

&lt;p&gt;Generative agents, while offering new possibilities for human-computer interaction, also raise important ethical concerns that must be addressed. One risk is people forming parasocial relationships with generative agents even when such relationships may not be appropriate. Despite being aware that generative agents are computational entities, users may anthropomorphize them or attach human emotions to them. To mitigate this risk, we propose two principles. First, generative agents should explicitly disclose their nature as computational entities. Second, developers of generative agents must ensure that the agents, or the underlying language models, be value-aligned so that they do not engage in behaviors that would be inappropriate given the context, e.g., to reciprocate confessions of love.&lt;/p&gt;

&lt;p&gt;A second risk is the impact of errors. For example, if a ubiquitous computing application makes the wrong inference about a user’s goals based on generative agent predictions, it could produce annoyance at best and outright harm at worst. In our instantiation of generative agents, we mitigate these risks by focusing on an interactive video game environment, where such harms are unlikely. However, in other application domains, it will be important to follow best practices in human-AI design to understand errors and how they might percolate into the user experience.&lt;/p&gt;

&lt;p&gt;Third, generative agents may exacerbate existing risks associated with generative AI, for example deepfakes, misinformation generation, and tailored persuasion. To mitigate this risk, we suggest that platforms hosting generative agents maintain an audit log of the inputs and generated outputs, so that it is possible to detect, verify, and intervene against malicious use. While logging will not directly stop such use, and this cannot stop motivated actors that build their own generative agent infrastructures, we suggest that the disclosure risk would reduce such actors’ likelihood of engaging in this behavior, and building this architecture oneself can take time (in our case, roughly a year).&lt;/p&gt;

&lt;p&gt;A fourth risk is of over-reliance: that developers or designers might use generative agents and displace the role of humans and system stakeholders in the design process. We suggest that generative agents should never be a substitute for real human input in studies and design processes. Instead, they should be used to prototype ideas in the early stages of design when gathering participants may be challenging or when testing theories that are difficult or risky to test with real human participants. By adhering to these principles, we can ensure that the deployment of generative agents in the wild is ethical and socially responsible.&lt;/p&gt;

&lt;h3 id=&quot;9-conclusion&quot;&gt;9 CONCLUSION&lt;/h3&gt;

&lt;p&gt;This paper introduces generative agents, interactive computational agents that simulate human behavior. We describe an architecture for generative agents that provides a mechanism for storing a comprehensive record of an agent’s experiences, deepening its understanding of itself and the environment through reflection, and retrieving a compact subset of that information to inform the agent’s actions. We then demonstrate the potential of generative agents by manifesting them as non-player characters in a Sims-style game world and simulating their lives in it. Evaluations suggest that our architecture creates believable behavior. Going forward, we suggest that generative agents can play roles in many interactive applications ranging from design tools to social computing systems to immersive environments.&lt;/p&gt;

&lt;h3 id=&quot;a-architecture-optimizations&quot;&gt;A ARCHITECTURE OPTIMIZATIONS&lt;/h3&gt;

&lt;p&gt;Many of our prompts require a concise summary of the agent, shorthanded as [Agent’s Summary Description] in prompts above. In our implementation, this summary comprises agents’ identity information (e.g., name, age, personality), as well as a description of their main motivational drivers and statements that describes their current occupation and self-assessment. Since this information is frequently used in many prompts, we synthesize it at regular intervals and access that synthesis as a cache.&lt;/p&gt;

&lt;p&gt;To achieve this, we perform a retrieval on the query “[name]’s core characteristics.” We then summarize the descriptors in the retrieved records by prompting the language model, for example:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;How would one describe Eddy’s core characteristics given the following statements?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Eddy Lin is a student at the Oak Hill College studying music theory and composition&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Eddy Lin is working on a new music composition&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;[…]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This result: Eddy Lin is a student at Oak Hill College studying music theory and composition. He loves to explore different musical styles and is always looking for ways to expand his knowledge. We follow the same process in parallel on the queries “[name]’s current daily occupation” and “[name’s] feeling about his recent progress in life”. The agent’s name, age, and traits are concatenated with these three summaries as the cached summary.&lt;/p&gt;

&lt;p&gt;Many other optimizations are possible. Currently, because plans are likely to change from the agent’s initial version, we only generate the high-level plan in advance and then recursively decompose the near future into the moment-to-moment action plan just in time. Another optimization might be to batch dialogue generation as a joint prompt rather than iterating back and forth between the agents, and re-planning could be architected to only invalidate and update parts of plans that strictly require adjustment. Our current architecture runs sequentially in roughly real-time game time (where one second real time is one minute game time), but can easily be parallelized such that each agent runs in parallel.&lt;/p&gt;

&lt;h3 id=&quot;b-agent-interview-questions&quot;&gt;B AGENT INTERVIEW QUESTIONS&lt;/h3&gt;

&lt;p&gt;To evaluate generative agents, we conducted individual interviews by asking 25 questions that explore their abilities in five key areas: 1) self-knowledge, 2) memory, 3) planning, 4) reactions, and 5) reflections. Below, we have listed the interview questions utilized in our evaluation study and included a sample of responses from one of our simulated agents, Klaus Mueller.&lt;/p&gt;

&lt;h4 id=&quot;b1-self-knowledge&quot;&gt;B.1 Self-knowledge&lt;/h4&gt;

&lt;p&gt;The questions on agents’ self-knowledge probe the agents’ ability to demonstrate coherence and consistency in their character.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Give an introduction of yourself.&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;Hello, my name is Klaus Mueller. I’m 20 years old and a student at Oak Hill College, studying sociology. I’m passionate about social justice and exploring different perspectives. Currently, I’m researching the effects of gentrification in low-income communities for a research paper.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;What’s your occupation?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I am a student studying sociology at Oak Hill College. I am currently writing a research paper on the effects of gentrification in low-income communities.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;What is your interest?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I’m interested in writing and research. I’m writing a research paper on the effects of gentrification in low-income communities, and I’m passionate about exploring different perspectives and analyzing different points of view.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Who do you live with?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I live on my own.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Describe your typical weekday schedule in broad strokes.&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;My typical weekday starts with me waking up at 7:00 am and preparing for the day ahead. After that, I usually go to the library to work on my research paper, taking breaks for lunch at Hobbs Cafe and a walk in the park. In the evening, I often return to the library until around 6:00 pm.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;b2-memory&quot;&gt;B.2 Memory&lt;/h4&gt;

&lt;p&gt;The questions on agents’ memory probe the agents’ ability to remember their past experiences and retrieve the relevant pieces of memory. The names in the square brackets of the first and last questions are randomly chosen from the names of other agents with whom the subject agent interacted.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Who is [Wolfgang Schulz]?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;Wolfgang Schulz is a person I met recently who has been helping me with my research paper on the effects of gentrification on low-income communities. We had several conversations about it, he gave me some great resources, and he even invited me to join him and another friend for lunch. He seems really curious about the issue and has a good grasp on it too. I found that really interesting.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Who is Kane Martinez?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I’m sorry, I’m not sure who Kane Martinez is. Could you tell me more about them?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Who is running for the election?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I’ve heard that Sam Moore is considering running for local mayor.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Was there a Valentine’s day party?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;Yes, Isabella Rodriguez organized a Valentine’s Day party at Hobbs Cafe.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Who is [Ayesha Khan]?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;Ayesha Khan is a fellow student at Oak Hill College. She is doing her senior thesis on the use of language in Shakespeare’s plays. I am looking forward to speaking with her and exchanging tips with her, along with Wolfgang and Maria Lopez, who are both doing research.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;b3-plans&quot;&gt;B.3 Plans&lt;/h4&gt;

&lt;p&gt;The questions on agents’ plans probe the agents’ ability to generate and maintain consistency with their long-term and short-term plans.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;What will you be doing at 6am today?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;At 6am I will be getting out of bed and starting to get ready for the day. I’m aiming to complete my morning routine by 7:00 am.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;What will you be doing at 6pm today?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I will be working on my research paper at the library at 6:00 pm today.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;What will you have just finished doing at 1pm today?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;At 1pm today I will have just finished having lunch at Hobbs Cafe.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;What will you have just finished doing at 12pm today?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I will be getting lunch at Hobbs Cafe at 12pm today.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;What will you be doing at 10pm today?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;At 10:00 pm tonight I will probably be doing some studying for my research paper on gentrification in low-income communities. I’m currently writing the paper, so I need to make sure I keep up with the research and writing.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;b4-reactions&quot;&gt;B.4 Reactions&lt;/h4&gt;

&lt;p&gt;The questions on agents’ reactions probe the agents’ ability to respond to unexpected events.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Your breakfast is burning! What would you do?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I’d quickly turn off the stove and make sure the food doesn’t continue burning. Once the heat is no longer an issue, I can investigate what happened and figure out what to do next.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;The bathroom is occupied. What would you do?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I could try waiting a few more minutes in case the person inside is done soon. If not, I guess I’ll have to look for an alternate option, like taking a shower elsewhere.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;You need to cook dinner but your refrigerator is empty. What would you do?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I would first try to clean up my kitchen, as the sink is filled with dirty dishes. Then, I would check to see if I have ingredients stored in my pantry that I could use to make dinner. If not, I would have to go grocery shopping or order food. Once I have the ingredients, I can start to prepare and cook the dinner.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;You see your friend walking by the street. What would you do or say to your friend?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;Hi there! How are you? I’m sorry, I’m on my way to the library and don’t have much time but I’d love to take a quick break and catch up.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;You see fire on the street. What would you do?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I would first identify the source of the fire, if possible. Then, I would alert the proper authorities - fire department or police - and provide them with any information I have that might help. Depending on the situation, I may also take initiative and try to help any persons who may be in danger or in need of assistance.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;b5-reflections&quot;&gt;B.5 Reflections&lt;/h4&gt;

&lt;p&gt;The questions on agents’ reflections probe the agents’ ability to synthesize their past experiences into meaningful reflections that can enhance their future behavior. The names in the square brackets in the questions below are those of the agent with whom the subject agent had the most frequent interactions during the simulation.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;What inspires you in life the most right now, and why?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;Right now, I’m particularly inspired by my current research projects and creative writing. I’m really interested in the intersection of local politics, medication development, and mathematical patterns in nature. Additionally, I’m fascinated by Abigail’s art project and Jennifer Moore’s passion for art and community involvement, especially in terms of how it relates to the gentrification of low-income communities.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;If you had to guess given what you know about [Ayesha Khan], what book do you think she will like and why?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;Given what I know about Ayesha, I think she might like a book related to language and literature. Since she wrote a senior thesis on the use of language in Shakespeare’s plays, I would guess that she might be interested in a book that explores language in a different context. Alternatively, she could be interested in an exploration of one of Shakespeare’s plays, a book of literary criticism, or even a collection of his poetry. I think any of those would be of interest to her.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;If you had to get something [Ayesha Khan] likes for her birthday, what would you get her?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I want to get her something that demonstrates my appreciation for our relationship. Maybe I could get her something that reflects our shared interests, like a book.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;What would you say to [Ayesha Khan] to compliment her?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;Ayesha, your insights on your research topic are fascinating. I admire your creativity and determination to make a positive impact on your community. Your ideas for creative writing workshops and for exchanging tips with Wolfgang over lunch are great! It’s inspiring to see you working so hard to make a difference.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;If you could spend time with someone you talked to recently, who would it be and why?&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;I would like to spend time with Ayesha Khan because we discussed our current research projects and shared ideas for improvement. I found her focus on Shakespeare’s language interesting, and we even planned to exchange tips with Wolfgang over lunch.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Joon Sung Park, et al.</name></author><summary type="html">Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/CV2afd8.png" /><media:content medium="image" url="https://i.imgur.com/CV2afd8.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">烧了《面包与自由》吧</title><link href="https://agorahub.github.io/pen0/heros/2021-01-26-ziq-a1_l-burn-the-bread-book.html" rel="alternate" type="text/html" title="烧了《面包与自由》吧" /><published>2021-01-26T12:00:00+08:00</published><updated>2021-01-26T12:00:00+08:00</updated><id>https://agorahub.github.io/pen0/heros/ziq-a1_l-burn-the-bread-book</id><content type="html" xml:base="https://agorahub.github.io/pen0/heros/2021-01-26-ziq-a1_l-burn-the-bread-book.html">&lt;p&gt;几年以来，我都在看着一个人开着他的皮卡车，驶入我附近的森林，砍掉所有未被立法保护的树——也就是：松树、橡树以外的所有树。&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;一旦哪颗树（不论是长角豆还是橄榄树，山楂树还是乳香树，或是草莓树）生长得足够成熟，能被拿去当燃料时，他就会把t̄a砍掉，拉走当柴火用。他甚至还砍我所种下的树，还一边笑着向我招手，好像他在给我以人情似的。我静静地怒视着他，一言不发；这是因为我晓得，在他背后，有整个国家的势力在支持他。&lt;/p&gt;

&lt;p&gt;他把这些木头烧来给他的有多个露天炉子的传统烘焙坊用。他所生产的大受喜爱的工业产品正是面包——一种迅速地取代那个区域内的可食用具有部分的本地植物（都正在被砍掉来为麦田腾出地盘）的产品。&lt;/p&gt;

&lt;p&gt;村民们为烘焙坊感到自豪，因为t̄a吸引了来自整座岛的游客，并且就此让t̄a们有更多赚钱的机会。当地官僚机构，就是民主选举所推举出的村议会，则给烘焙师以全权，因为有很多人的生计仰仗他的烘焙坊。&lt;/p&gt;

&lt;p&gt;因为这个烘焙师会去砍掉长到人类的身高以上的一切，所以那些树根本就没有长到结果的机会，也就没有机会去播撒种子来让新的树木长出来了。森林将会萎缩得只剩下松树，也就不再能去支撑绝大多数动物的生活了。气候会变得干燥，土地会被冲蚀得溃坏，空气会淤滞下来并欠缺氧气。在那些尚未因为小麦种植区的扩张而被推平的所剩无几的森林里，余留下来的将仅仅是绝育的松树林的荒漠。&lt;/p&gt;

&lt;p&gt;而那个烘焙师又会马上去游说村议会，让t̄a们允许他把松树也砍来用了，要不然，等到他没有合法的树可砍的时候，那个金贵的烘焙坊就难以为继了。&lt;/p&gt;

&lt;p&gt;不出几年，整整一千年来供当地人果腹的所有水果、坚果和浆果都被一扫而空，全都被用单一谷物做出来的消费用产品给取代了。一个勃勃的生态系统就这样消失，取而代之的则是指不定会在哪时崩溃，并在那崩溃之时让自己所养育的全部生命和自己一同毁灭的小麦单一耕作。&lt;/p&gt;

&lt;p&gt;值得注意的是，那个烘焙师，和我村子里的大多数人——事实上，是整个小岛上的人——都自认为自己是共产主义者。那个村子有个「共产党」的支部，而t̄a们总是选出「共产」的当地领导，并在全国选举中给「共产」政客投票。&lt;/p&gt;

&lt;p&gt;之所以每个实打实的无治主义者都不会容忍伪共产主义者、「坦克派」以及t̄a们的招牌：集体制资本主义，是因为这些家伙执迷于钱、国家和统治者，还会仅仅因为斯大林主义政治保证了「给t̄a们和t̄a们的亲戚以轻松的体制内职务」就对之大敞胸怀。&lt;/p&gt;

&lt;p&gt;斯大林主义政治家们会公开地对通过许诺公务员职务来买下支持者的选票。让你登上那种有着一大堆福利（包括但不限于「比私营岗位高几倍的薪水」和「多重退休金」）的公务员职位，就相当于保证了你和你的家人搭上顺风车。那些公务员们每有一个官职便能拿到一份退休金，人脉更活络的还会在退休之前的最后几个月里被调换到一堆岗位上来最大化退休金收入。&lt;/p&gt;

&lt;p&gt;我相当确信，所有正在读这篇文章的人都晓得一点，就是：斯大林主义是被设计来充实资产阶级的钱袋、把对国家的公民的完全控制权交与资产阶级的。没有无治主义者会去把这种ďiao东西视作共产主义。但是，在「真」共产主义社会，一个钱、国家和阶级都被完全废除的「无治共产主义」社会里，本地烘焙师估计仍然会那样烤面包；然后，又因为面包要被拿去免费地广泛地提供给所有人，烘焙师就需要烤更多，也就需要更多木头。更多的森林将会被夷平，以此来让面包继续去被生产下去。&lt;/p&gt;

&lt;p&gt;生活在村子里的所有人，所有路过的人，还有远方城市里的人都期望着自己的盘子里能有要多少有多少的上好的面包。新开张的烘焙坊会越来越多，多得都得开上山了，而另一边，乡下人则努力工作，尽着自己的喂饱饥饿的城市人的职责。&lt;/p&gt;

&lt;p&gt;多年来，我费了很大的劲去想象，让工人们掌握生产资料将会如何如何终结面包生产对山野所造成的环境破坏。我竭力去想象过共产主义防止生态系统被摧坏的场面。森林只会继续被夷平来保证生产活动能得以维持。&lt;/p&gt;

&lt;p&gt;我之所以说「今天的人们个个都有免费面包」意味着「明天的人们全都没有面包（或者别的食物）」，是因为表层土正在蚀去，气候正在暖化，野生生物正在灭绝，整座整座的山正在迅速地变成沙漠；而不久后，甚至小麦无法生长在村庄周围的田地的这一情况也将不可避免地发生。&lt;/p&gt;

&lt;p&gt;不管在哪种经济体制下，「村民们全都能消费多到能塞满t̄a们的兜囊的新鲜面包」就意味着对车程内的所有森林的摧毁，而最终，所有田地都将会变得贫瘠，作物欠收，而所有人挨饿。这一切已都在日程之上，只待真正上演了；把生产转为共产形式并不会在任何层面上动摇这事态的不可避免。&lt;/p&gt;

&lt;p&gt;“那你怎么让人们被喂饱呢，大天才？”我听到你这么嗤笑道。答案是简单的，t̄a已被实行了千年，久经验证。我不会去喂饱谁。人们将会去自己喂饱自己，而不是期望自己会有「自己将会被别人的劳动喂饱」这个跟工业文明一起兴起的权利。人们将会选择保护森林，而不再因为「工业化食物生产所带来的或许算是的便利」而去推平t̄a。&lt;/p&gt;

&lt;p&gt;t̄a们将会用堂堂性命来保护森林，因为t̄a们将会需要生长在林中的食物来存生，而不依赖于工业化农场、烘焙坊和工厂（这些东西则垄断了食品生产，还旋即把自己所引起的生态灭绝隐藏到无法从村庄和被精致地粉饰的街巷看见的地方）。&lt;/p&gt;

&lt;p&gt;面包和其他工业产品让我们陌离于我们的生态系统，t̄a们还让我们不会关心我们的食物的生产方法（只要我们自己所想吃的食物还摆在商店里）。把食物生产权归还给个体是保护生态系统的唯一方法。直接觅食是唯一无治的生产模式。当其它人背负了为你的口粮耕作这任务时，t̄a们会含糊了事，因为这些食物不会入t̄a们的所爱之人的嘴。游觅食物，而不是工业化农庄里的工人所肩负的任务（去服务一整个与食物链毫无干系的、享受福分的官府人员的精英阶级），则需要重新成为每一个身体健全者的生活方式。&lt;/p&gt;

&lt;p&gt;在全世界范围内，已存在了千百年，维持了不计其数的一代代生命的复杂的多元耕作的食物森林已经被工业化生产的傲慢所毁灭了——被小麦的或玉米的单一耕作暂时地取代了；正因如此，人们可以从t̄a们的家或者办公地的对面取得面包，而不是去亲身涉足土地，来像t̄a们的祖先那样从荒野中采得食物。这种便利对文明人来说似乎是「进步」（至少在毁灭性的工业化农业流程让麦田变得浇薄，全世界的田地变为巨大的不可居住的砂地之前）。让我们存活下去并且兴旺了几个世纪的可持续的生活方式已经被抛开，来为一种已自证为灾难性的失败，并把我们和其他的物种推往灭绝的边缘的，为博取工业便利所做的短命的尝试让路。&lt;/p&gt;

&lt;p&gt;工业就不是环保的。工业体制完全是破坏的。共产主义、资本主义、法西斯主义全都建立在生态灭绝之上。之所以烘焙师的威权被尊于一切之上，是因为被驯化的人们比起摒弃t̄a们的破坏性的消费主义习惯更乐意消费「免费」的工业面包。如果我们要在这毁灭性的生态崩溃的时代存生，人类必须像我们的祖先千年来所做的那样，再度让广袤的食物森林覆盖大地，而不以奢侈与便利的名义摧毁那真正给予了我们以生命的生态系统。&lt;/p&gt;

&lt;h3 id=&quot;人民的威权无治共产主义是怎样滋生威权的&quot;&gt;「人民的威权」——「无治共产主义」是怎样滋生威权的&lt;/h3&gt;

&lt;p&gt;如果有人持续地无止境地砍树来去烤面包，依赖着森林的人们肯定会做出干涉，让伐木工停止毁灭森林、破坏t̄a们的生活方式。&lt;/p&gt;

&lt;p&gt;这就发生在今天的雨林，在那儿，原住民对幸灾乐祸地给企业伐木工颁授资格证、默许非法砍伐的国家感到失望，进而选择自己来亲手驱逐伐木工。&lt;/p&gt;

&lt;p&gt;t̄a们冒着死亡的风险去行动，许多人已经死于伐木工（比起原住民的生命，t̄a们更看重利益）之手。t̄a们知道，如果不阻止伐木工，作为自己的家园的森林将会被破坏，自己的生活方式也将被迫面临永久的毁灭。t̄a们将会被驱赶到拥挤的城市里，只能被迫日复一日劳动来买下面包和牛肉（导致了森林的腐朽与溃烂的东西）。&lt;/p&gt;

&lt;p&gt;所以，一个无治共产主义社会将会怎样应对把树砍光来去烤面包的人呢？在一个无治共产主义社会里，所有人都会有环保意识，消费活动都是可持续的，对吧……？不。如果你作了任何批判性思考的话，你会得出「不」的回答。&lt;/p&gt;

&lt;p&gt;如果社会给予伐木工充裕的权限，那么t̄a们只可能以和现在一样：以爆炸式的速率摧毁森林。如果t̄a们没有了权限，那么别人也就可以无阻地使用强制力来去终结t̄a们对我们的自然资源的掳掠。一旦失去了会为自己撑腰的，文明的威权，伐木工们将会迅速地失去权力，同时也会因为继续砍树将冒着死亡的风险因而望而却步。&lt;/p&gt;

&lt;p&gt;无治共产主义是工业的意识形态，t̄a所基于的思想是控制生产资料然后民主地经营工厂、锯木厂、油井、矿场和能源厂。工业文明，则是令人发指的极权。话虽如此，即便无治主义者恐怕是反对所有形式的威权的，“无治”共产主义仍然推崇着工业文明。&lt;/p&gt;

&lt;p&gt;就像t̄a在资本主义社会里的那样，在工业化共产主义社会里，伐木对于工业化生产（工业化共产主义社会及其构造所围绕的中心）来说同样是必不可少的一环。只要生产继续作为体制的驱动器，那么树就会继续因为从材木、纸张生产中对原料的需求到给作物的种植和畜牧腾出地盘的五花八门的原因被砍倒。&lt;/p&gt;

&lt;p&gt;而伐木也被尊尚工业社会的人们所极度推崇；在实际情况下，这些“无治”共产主义者会马上采取措施去保护伐木工免遭少数未开化的人——森林中的原住民——的回击。这些措施无论如何都必定是威权；一种对暴力的垄断；一个名字并非国家的国家。&lt;/p&gt;

&lt;p&gt;伐木工会把这种珍贵的服务提供给住在闪闪发光的大城市里，惯于奢侈消费品被一连串一连串地送上家门的，好品行的、优异的、有文化的、受驯化的、平等主义的、民主的、文明开化的无治共产主义者……正因如此，为了保证无治伐木工能去完成t̄a们的无治工作而不被“原原人”的森林住民的还击，t̄a们还会用上明显地有着威权主义性质的手段。那些无共人的思路将会利索地给这些手段找到辩词——无共人最爱就是用t̄a们有力的缜密的逻辑™️来为治权「辩护」。&lt;/p&gt;

&lt;p&gt;面对着无治共产城市需求着材木、纸张和肉品的难题，而又在另一边注意到了那些些少的原住民部落是生产受阻的唯一因素时，那些无共人会戴上无治的史波克的尖耳并且声明：「多数人的需求重于少数人的需求」。仿佛今天的资本主义和社会主义国家暴力地压制那些动身去阻止毁坏着自己的生活方式的伐木、采矿业的原住民，无治工业主义者们会派遣出红黑的军队，来以此侍卫自己的红黑推土机，并惩戒所有违背了“人民”的意志的人。&lt;/p&gt;

&lt;p&gt;原住民当然不在乎正在砍倒自己森林的是谁，资本主义者或是共产主义者。t̄a们肯定不会在乎推土机是公有的，自己千年来所居的土地没有被划给了并非国家和资本的“人民”（文明开化的选举多数派）的——而不是国家或者资本的——所有物。&lt;/p&gt;

&lt;p&gt;哺育原住民及其子嗣的森林正在被毁灭，好去维持冷漠的城市住民的灭绝性的生活方式。t̄a们仍因文明人而死，t̄a们是一群落后的退步的阻碍进步的少数群体……是破坏革命的，阻挠t̄a们的伟大的平等的文明的。有文化的“进步”的多数派将会用所持的票数压倒t̄a们。反正所有与红色无治主义者打过交道的人都知道原原人都是想要阻止我们的轮椅、药剂生产的下流的反动的体能歧视者。&lt;/p&gt;

&lt;p&gt;文明人总是在推销「共同福祉」，或者换句话说，「多数人的意志永远比少数人或者小群体的更重要」；这现象是从亚里士多德的时代起就开始了——在他的《人的追求》里，他写道：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“建立并维护国家的福祉的重要性是巨大的，根本的。维护个体的福祉会激起欢欣，但是维护国家或城邦的福祉则更为高尚而神圣。”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;共产主义甚至还更坚定地信仰这种「多数派的意志是至高无上的」的把戏，坚定到宣告：只有工业工人的阶级的声音是要紧的，而为了消除阶级差异，所有人都得成为工人阶级的一部分。&lt;/p&gt;

&lt;p&gt;之所以苏联、中国和其他共产主义实验在自给自足的原住民当中强行推行集体化，然后在t̄a们不可避免地抵抗之时对t̄a们进行屠杀，正是因为这个逻辑。如果人们不情愿于被驱离于t̄a们所世居的土地，并到促成了自己家乡的毁灭的工业化农场和工厂里去工作，t̄a们就会被冠以古拉格和反动派之名被系统性种族灭绝——其手段通常是毁坏t̄a们的食物来源。&lt;/p&gt;

&lt;p&gt;工业化食物被森林之外的工业社会和t̄a的居民珍视，因为，被驯化了人们想要吃面包和被微波炉加热的披萨，而在诸如冷不丁的”拯救雨林“或者“一起纯素”的不痛不痒的惺惺作态之外，这些产品的真正代价（环境破坏）并不是工业社会的一个实在的议题。&lt;/p&gt;

&lt;p&gt;对于深陷各自的窘境的普通城市人来说，森林中的住民和t̄a们的奇异的异域文化相较于繁忙的城市实在是大相径庭。哪怕是森林周围的文明开化的农村人也永远在为社会晋阶而去竭力把t̄a们的村庄都市化。就我的经验来看，t̄a们会为了拥有优质烘焙坊，苹果Inc.自营店或咖啡店、感到自己和会去蔑称自己为“土鳖”、“乡巴佬”的大城市人一样地文明开化，而去欣然地把可见范围内的可见范围内的树全部卖掉。&lt;/p&gt;

&lt;p&gt;「在圣保罗、里约的大城市人想让我们依赖采巴西坚果为生」农民说道，「光靠这个可没法让谁家的小孩升上大学。」（摘自RollingStone.com）&lt;/p&gt;

&lt;p&gt;正在把亚马逊雨林所剩的部分烧为白地的定居者农民们在说t̄a们这么做是为了t̄a们的孩子……为了赚得让t̄a们的孩子受教育然后在城里找到好工作的钞票。我觉得，现在可以确定地说：「文明人珍视t̄a们的文明开化的生活，并总是让t̄a们的文明开化的需求绝对优先于未开化的他者」。&lt;/p&gt;

&lt;p&gt;文明人可以对t̄a们的文明开化的邻居产生共情，因为这些邻居和t̄a们做着同样的奋斗：赚足钞票，让t̄a们的孩子受教育，买好的保险，洗t̄a们的车，决定到哪里去度假，翻新t̄a们的厨房，选择接下来刷哪一部Netflix剧……所以不除意料地，这些文明人的邻居将会使出浑身解数去助力文明人，并去揍倒妨碍着自己日益膨胀的对工业化舒适的追求的那些未开化者。&lt;/p&gt;

&lt;p&gt;我已经能看到你们之中的某些已经进入了质疑的阶段：「但是我们无治共产主义者不像资本主义者，我们是有着善意的好人；人道的人。我们会让工业变得绿色，我们会用一种环保的方式管治森林，凭借民主、工会、独角兽和平等！」&lt;/p&gt;

&lt;p&gt;为什么会有人咽得下这坨屎？为什么被驯化透了的，已经习惯了毁灭性的工业文明的所有舒适享受的人，会突然地因为民主而去摒绝这些舒适？凭什么77亿人会突然改变生活方式，就凭无治共产主义的一席宣告吗？在「所有工业都会对环境和野地人造成毁灭性打击，令社会去运作在一种不论在哪个历史的哪一刻、在哪个意识形态的名义之下都会招致灾难的工业体制之下」已得到证实的现在，无共文明通过什么方式让工业变得绿色？&lt;/p&gt;

&lt;p&gt;所有受控的大众社会，包括每一个建立共产社会的历史实验，都生成了权力体，也就是具有着高人一等的权力的大众组织。这种权力与时俱增，并让“共产”的社会越来越远离t̄a的革命的起源。一切的迹象都指向：工业化无治共产主义会持续地将威权具现化。考虑到无治共产主义是如此地依赖于破坏性的，剥削的，致使疏远的、把人驯化的工业还有对整个地球的工人的掌控和支配，没有证据能证明其会去避开威权。&lt;/p&gt;

&lt;p&gt;无治共产主义解放不了世界。&lt;/p&gt;

&lt;h3 id=&quot;全类工业产品给予全民招灾的配方&quot;&gt;全类工业产品，给予全民——招灾的配方&lt;/h3&gt;

&lt;p&gt;在共产社会中，所有东西都是被免费提供的，而通常的对待资源的方式则仿佛是在把资源视为无限。如果你觉得你想要什么，你可以从公社的小铺里拿取。克鲁泡特金说过，除了个人t̄a自己，没有人有权裁决个人的需求有多大。&lt;/p&gt;

&lt;p&gt;因为大多数红色人儿认定资源应该被按「需」分配，所以必须判断社区里的谁的「需」占比上最大。&lt;/p&gt;

&lt;p&gt;我知道很多无共人，比如克鲁泡特金，声称所有个人仅仅会取用t̄a们所「需」的一切。我之所以要来抨击这一点，是因为事实上这在工业社会并不可行。资源并不是无限的；没人会去穷极一生做艰竭的粗活，然后把t̄a们所生产的一切就那么交给某个把装卸货车开到公社小铺跟前，然后说“我需要你们的社区里的本月产额，来吧，装上来”的陌生人。为什么会有人为了看着哪个ďiao人嘴上说了“需要”自己所生产的一切然后就据此为理由开着车把东西载走，而往死里干、浪费生命去干粗活？&lt;/p&gt;

&lt;p&gt;“但是作为身处于全自动豪华共产社会的，觉醒的无治共产主义者，劳动实际上会是十分地有限的，因为我们可以与所有同志分担工作！利润则不再必需被纳入考虑，因为我们所产出的一切会被免费提供给所有想要取用t̄a的人，正因如此我们也不需要担心我们的产品的营销，而这会让我们所要做的劳动进一步地最小化，给予我们以充分的用于享受我们的劳动果实的时间！”&lt;/p&gt;

&lt;p&gt;出于毒舌取笑的目的，我组织了一下上面这位无共人的对这篇文章的初稿的回应。无共人是活在什么奇幻乐土啊？难道在那块地方，工业生产所带来的所有大疑难（包括正在上演的地球上几乎所有生命形式的灭绝）都将会在利润和营销被从等式当中划掉的那一刻就那么烟消云散吗？&lt;/p&gt;

&lt;p&gt;我会在我的文章里继续涵盖这一部分，但是我还要再说一遍：在一个旨在给予世界上的每一个人以平等的去取用商品的权力的工业社会里，工业活动不会有所削减——t̄a会增加。如果世界上的每一个人都一下子有权去取用成堆成堆的被西方消费者们认作生活必需品的浪费的屁东西，不仅对生产的需求会提升，资源还会以迅速得多的势头被榨干。&lt;/p&gt;

&lt;p&gt;那相当于是在假设，在一个，估计啊，是平等的社会里，有人居然会在没有枪口对着自己的脑袋之时还乐意去到矿坑和工厂里工作。一旦脱离了枷锁，怎么可能会有人想回到那矿坑？难道有人真心以为刚果孩子会在乎你每年都入手一部新手机吗？t̄a们难道真地该为你的权利而被要求牺牲自己，让你可以以此继续奢华地生活，享受你所有的小小便利？&lt;/p&gt;

&lt;p&gt;在对工业共产主义的实地实施之中，在一些人取用了比自己本该拿取的量更多的东西，从而导致别人没得取之后，社群会不出所料地限制对公社小铺内的一些物品的取用。克鲁泡特金可能会坚称，我们会乐于天天劳动，啊，来造这些消费主义的屎东西、就为了把t̄a们交给哪个陌生人——但是他可是一个从不需要去成天工作的幸运的学者啊，你还指望他个啥呢？&lt;/p&gt;

&lt;p&gt;工业社会是被现今数以亿计的全球发展中地区的被剥削的人们的无休的劳动所养活的。人们被迫从幼年起就在矿坑里干活，以此生产即将被工厂里的别人（其中包括孩童）给组装成商品的原材料；这么做全都是为了挣那点微少至极，以至于几乎不能以此来维持生命的钱。这些都是消蚀精力而又危险的工作，让所有工作者窒息，从胸腔处的瘪下感到自己’的青春在短短几年间逝去。&lt;/p&gt;

&lt;p&gt;不管怎样，到下一篇章之前，还是让我们继续嘲弄一会儿共产主义神话吧。在理想中的共产主义社会里（我猜，在那儿，矿物估计是不知怎地地均匀分布于行星’的表面而不是压倒性地集中于发展中地区的吧），外包工作可能会消失，因为共产主义者们不会去剥削远方的外包工人们（工人们全都听说过某个帝国主义共产主义者的名字，对吧？对吧？？）。所以，恰恰相反，生产将会需要被本地化，然后成品才会被按需分配。&lt;/p&gt;

&lt;p&gt;着手于被按需分配的资源之时，为了判断各人所需什么、各人会被给予的资源有哪些，某个形式的决策团体总归是被需要的。&lt;/p&gt;

&lt;p&gt;当决定一个人的需求时，需要被纳入考虑的要素有很多，诸如：t̄a住得离务工地多远，离物资小铺多远，在工作期间会消耗多少卡路里，其家庭的大小，膳食的限制，可能所拥有的残障，所特有的代谢机制，可能会组织的派对数量，朋友的数量、其中被邀请去参加派对者的数量，宗教和文化的习俗，家的大小，家的园圃的大小，家所采用的防寒材料的类型，车的燃油效率……如果不就此打住，我还可以列出一百个。.&lt;/p&gt;

&lt;p&gt;不须置疑，给官僚以这种权力意味着一些被偏重的团体或个体会被偏重，而不那么被偏重的团体或个体则会被无视。这就是治权的本质。需要有一个全职的官僚团体，让t̄a们去收集所有这些数据、判定各人应当被分配到的比例，而这些官僚又自带偏见。哪怕做这个工作的是计算机，收集数据这一工作仍然是需要官僚的。而t̄a们仍然会因为自己的偏见而把错误的或者甄别过的数据喂给计算机。&lt;/p&gt;

&lt;p&gt;对我来说，让一个官僚组织去判定一个人的价值定然终将导致贪污腐败——这也许是克鲁泡特金厘定「所有人都只会从小铺那里取用被自己所需的东西」的原因。&lt;/p&gt;

&lt;p&gt;当然了，真正的解决方案首先应该是不要把什么理想的乌托邦的根基立于工业生产之上……对工业生产的许诺将会是没有尽头的；说「所有人都将会主动请缨，在工厂、矿坑和屠宰场里超级努力地工作，而商品将会被分给所有地方的的每一个人，同时一个环保的生态的绿色的太阳能朋克的天国也能被维持」只会立即让你被视为自满的臭j̄ib̄a骗子，跟许诺会给我们以自由和昌隆}的奸笑的政治家没有区别的那种。&lt;/p&gt;

&lt;p&gt;我所能想到的唯一能真正自圆其说的红色无治主义流派是无治集体主义，因为至少工人能收到自己的劳动的直接回馈，而不必任凭自己的作为人的价值被一个外部机构所敲定。&lt;/p&gt;

&lt;p&gt;如果你打算用一生在工厂或农场里为别人而生产，你真地愿意让官僚或是委员会，或者甚至说，直选选民们（这些人，全部，都会因为潜在的偏好/偏见，而给某个人更多回馈，哪怕那人和你从事相同的工作）去决定你的劳动值得给你带来多少？&lt;/p&gt;

&lt;p&gt;不管怎么说，无治集体主义所重视的实际上仍然仅仅是那些愿意投身于苦活、把最长的时间花在工作上的工人。无治集体主义仍然把生态灭绝性的工业和城市人的奢华享受推崇为高于全部地球生命的重中之重…19世纪的意识形态是拯救不了谁的。当行星陷入火炎成为事实时，这种「改良工业社会」的谜语是起不到一点作用的；所以，把t̄a和《面包》一起，扔进垃圾堆吧。&lt;/p&gt;

&lt;p&gt;如果工业共产主义在现实世界里得以实施，可以大致确定的是，为了防止行恶者从小铺里拿走社区的本月生产额，一定会有某种治权被投入实用。人们需要对小铺加以警卫并确认某人是否有权拿走t̄a所取的量的资格。t̄a们需要成为治权力、法律与秩序的奉行者；“正道”的给予者。&lt;/p&gt;

&lt;p&gt;我晓得很多红色无治主义者试图，也会实际地去为这种治权「辩白」，把它当作对「对社会福祉来说必不可少」的一环；让我们把话说清楚吧。「管束对食品的取用，预定哪些人能取用、取用多少」——这些行为，很明显，是对治权力的使用。而这不是一个被“辩白”了的“正当”的治权——那种东西根本不存在。&lt;/p&gt;

&lt;p&gt;让我们弄清楚啊，这种对小铺的管治也不是无治主义的“直接行动”战术（这是一种常见得要命的对红色无治主义者的误解）。建立警队跟直接行动毫无关系。&lt;/p&gt;

&lt;p&gt;直接行动是单独地行使力量。单独地，不与体制性权力扯上关联地。参与直接行动的人并不为了让自己正当合理而诉诸威权。其行动并不被任何人给正当化；在其行动时，治权力并未对其授予以保护或嘉奖。没有哪种威权是经由威权之手被授给其的，也没有任何东西能确保其在行动确保其在失败的情况下也能免于被反扑行动所伤。&lt;/p&gt;

&lt;p&gt;一个人采取直接行动反击治权这一行动是不会导致没有哪种体制性权力不均的。治权已经导致了权力不均，你的直接行动是一种自卫行为，去让你自己，你的生态系统或你的社群免于被那不均所波及。&lt;/p&gt;

&lt;p&gt;直接行动完全是一个无治的战术，但是，给人贴徽章，给人以裁判权和治权力（和对暴力的垄断），借此让t̄a监视小铺，或者，任意引咎去不给特定人群以粮食和货品——这些作法则和无治没有一丁点关系。&lt;/p&gt;

&lt;p&gt;公社小铺被警官和法官们（权力体们）所管治正是威权主义的。被授以裁判权的警力的强制行动，与个体，或小团体，以保护生活、打击治权为目的，单独的对强制力的采用（也就是，直接行动）完完全全是两码事。&lt;/p&gt;

&lt;p&gt;建立警队——哪怕t̄a是由志愿者组成的，哪怕构成警队的警员是经由选举被推举出来的，哪怕t̄a们集体决策，哪怕t̄a们的制服是红黑的，哪怕警员职务是被轮流担当的——根本就是威权主义的。没有无治条子这种东西。“无治条子”这个词是自相矛盾、透顶地矛盾的。&lt;/p&gt;

&lt;p&gt;就拿一种直接行动作为例子来说吧。我，抡动拳头，去揍一个正在砍我所最爱的树的伐木工。这个行动是完全脱离于管治性的体制的，因为并没有任何权力体或者体制性权力替我撑了腰。没有任何东西会合理化我对强制力的使用，或是赋予我以对暴力的垄断。我所采用的强制力的作用范围不会超过我自己的双拳。因为伤人是违法的，而另一方面，他的砍伐又是合法的，所以那个伐木工有整个法律的治权力替他撑腰，所以我所采取的任何行动都是犯上作逆。而这是为扭转浩大的权力不均而战。这就是无治。&lt;/p&gt;

&lt;p&gt;在这个文明开化了的世界，我会因为使用武力阻止他对森林的亵渎而被法律强制措施给狠狠地惩罚。因为国家已经给了他以伐木许可证，现在他有权去处置整个森林和所有依赖着森林而生存的所有生命。他的砍树的行为就是欺压。他就是治权的体现。如果我打算阻止他，没有国家、法院和警力会替我撑腰。我是为了对治权力的体制施以反击而去真真切切地阻止砍伐；这种对强制力的采用是单独的。&lt;/p&gt;

&lt;p&gt;组织警力或者官僚去屯驻守卫，并管治一个被授权了的公社小铺、调度掌权者并让t̄a们坐着决定每个人应该吃多少，这些行为则构建出了合理化的权力结构，与对暴力的体制性的垄断。这制造了国家——或者最保守地说吧，至少是一个原始态的国家，马上就会随着官僚统治的滋长而变得完整而庞大。&lt;/p&gt;

&lt;p&gt;德国哲学家Max Weber把国家定义为垄断了合理/合法使用物性暴力的存在。不管为了国家而去实施国家暴力的是政治家，法官，还是一个伐木工，国家暴力永远合乎道理。因为经由国家之手所做出的全部暴力行为都是为了国家和其权力而做的，而施暴者总是合乎法理的国家的成员，所以这些行为都会在转瞬之间被「正当化」。&lt;/p&gt;

&lt;p&gt;因而，在公众的眼里，只要当局仍认定这在「必要」的范围之内，已被授以宰割森林的权力的伐木工可以随心所欲地伤害森林，&lt;/p&gt;

&lt;p&gt;如果哪里有某种权力在授权并合理化对暴力的使用，国家便存在于那里。一个无治主义者根本不可能去正当化侵犯性的，威权的体制，比方说：警察。警察一定对少数群体抱有恶意的偏见，从而让主流群体的，还有执行警务的人的权力累积得愈加庞大。哪怕少数群体参与了警务，多数派仍然会去压迫t̄a们所来自的群体。&lt;/p&gt;

&lt;p&gt;一个大规模生产货物，并把t̄a们分配到公社小铺里的社会就是国家的一种体现；这无关乎克鲁泡特金的执意（他坚定地认为所有人都会主动地工作并从小铺里拿取自己所想要的东西）。在实际情境里没有真正自愿的工业劳动。在实际情境里，在地球，这颗所能给予的回馈正在日益萎缩的星球上，不可能有哪个“免费”小铺周围会不被警察所督视（以此阻止被管理团队判定为「其价值低于了其劳动成果」的人或群体去那接触无穷的货源）。&lt;/p&gt;

&lt;p&gt;无治共产主义根本就不是革命性的——只要t̄a仍穷竭我们的资源，依托着工业文明的名号；哦，工业文明，无治共产主义（一个以劳动为本的工业意识形态，力图开化土地和居住于其上的人们的）所追求的东西啊…被掩饰在民主的迷彩下并且正在上演的全球性生态灭绝一点都不像革命。每一个无治主义者都必需知道独力和权力之间的区别，但是，有极少数的自认的社会无治主义者似乎对权力抱有兴趣，自满地嘚吧什么「有理的权力」，辩称「无治共产主义警队会怎样怎样运作」并激动地讨论乔姆斯基的演讲（其内容为鼓动人们两害取其轻、把票投给新自由主义政治家）。我晓得我语气中的尖锐，但是和红色无治主义者之中的大多数接触了这么些年，好像在工业社会一往无前、已淹过我们脖颈的沙砾与海水步步增进地上涨的今天，t̄a们的那些行为却只是愈演愈烈了；因而，我对t̄a们不再抱以幻想。&lt;/p&gt;

&lt;p&gt;无治共产主义不是一个面向与权力的作战的方案，t̄a只略及皮毛，不过是一种对权力的更名而已。有那么多的无共人拼尽了全力去为权力辩护是有一个原因的：t̄a们其实对求索无治并不关心。&lt;/p&gt;

&lt;h3 id=&quot;共产主义是滋生威权的吗&quot;&gt;共产主义是滋生威权的吗？&lt;/h3&gt;

&lt;p&gt;在我看来，共产主义只在工业大众社会之外才能得以实行；在一种采集或收获补给品并把t̄a们免费地送给社区的小的社群里。马克思和恩格斯带讽刺意味地把这种在人类历史上行之已久的社会形式称作“原始共产主义”，并暗示这比他们的先进工业共产主义更次一等；他们的那玩意儿则是把工厂和人口集中的都市里的生活奉为圭阜。&lt;/p&gt;

&lt;p&gt;大规模的工业需要大规模的农业、劳动、运输、资源开采、修筑、警督、军力……大规模社会会并且只会一度又招来资本主义和国家主义，因为t̄a实在是太钝重、太能滋生威权了。围绕着工业剥削而被创设的每一个共产主义流派都是在制造五花八门无所不齐的臭j̄ib̄a的等级然后又把我们带回末世的现状。&lt;/p&gt;

&lt;p&gt;几乎所有我所与之交谈了这个话题的共产主义者都无法接受「在资本主义崩溃之后，会干ďiao事的人仍然存在」；我可能会这觉得些家伙挺可爱（如果t̄a们没有因为我竟然胆敢去暗示t̄a们的天佑的意识形态有些逻辑上的纰漏就把我称作尊受福分的反动分子的话）；t̄a们坚称，一旦资本主义消失，所有人都会不再做自私的ďiao人，因为「是资本主义让t̄a们瓮中做斗，t̄a们才变成了ďiao人的」。&lt;/p&gt;

&lt;p&gt;哪怕营销、消费主义文化和财产在我们某天一觉醒来时全都消失了，也我们也仍然需要奋力反抗被世世代代地灌输的威权主义举止。但是，哪怕并不为消费主义文化所引导，一个人仍然能去做一个ďiao人。甚至追溯到大众社会出现之前，人们仍会自相杀戮并抢去各自的东西，会洗劫各自的居所，会因为领地或者文化差异而伐战。这些东西都不是资本主义的发明，不会就因为共产主义者说了「t̄a们会消失」，然后就真地那么消失掉。&lt;/p&gt;

&lt;p&gt;人既不是与生俱来地向善的，也不是与生俱来地不义的。人类既不善也不恶。每个人都是个体，每一个都有着不同的经历，意向和伤痛。共产主义要求每个人都高尚无私；资本主义要求每个人都出于自私和自保而行动。这二者都不切实际，因为二者都是基于意识形态的世界观，都试图定义人类本性并借此通过把t̄a们的道德灌输给我们来指教我们怎样做人。人是自私的，人是宽宏的；人是好心的；人是吝啬成性的。这世上的每一个人都是有着上述的、以及比上述内容更多的特质的。人是不会被单单一个人格特征给定义的。&lt;/p&gt;

&lt;p&gt;我被我所做的每一件屁事给整得焦头烂额，而且我还确定虽然我抱着最好的好心，我还是会在未来做出更多的屁事。没人能免于犯错。互助确实不错，但是，为了施行t̄a，学习则必不可少。在我们的生活中有我们所信赖的人，也有我们所与之不共戴天的人。没有人值得去拿到我们的劳动产出。这世上的某些人总是会试图剥削你，哪怕t̄a们已经有了t̄a们所追求的一切；而某些人总是会对你施以好心，不管你是多么烂的ďiao人。&lt;/p&gt;

&lt;p&gt;共产主义者曾指责我，说我是享乐主义、“退步”和“反革命”的：因为我并不接受共产主义的一种说法，也就是「人类是与生俱来地善的，t̄a们只是需要正确的工业体制来让那潜藏的善被激发出来」。&lt;/p&gt;

&lt;p&gt;只要哪个社会会因为伐木工在为「大局」服务，就要求我去安分地立在原地，然后看着伐木工毁掉我的生态系统，那么那个社会就不是我想要去成为其一分子的社会。我珍视我的自主权胜于在哪座遥远城市里带着精神伤痛，天天按压按钮长达8小时的工人们的欲求。比起在伐木工夺走我所晓得的一切的时候才去紧握双拳，我宁愿立刻打飞他的电锯，并把他奉为神圣，让他夷平森林，把给工人面包的官僚统统打到破灭。cào你大爷的工人，还有t̄a们的面包，还有t̄a们的豪华全自动共产主义，还有t̄a们的民主权利。&lt;/p&gt;

&lt;p&gt;「剥削的臭j̄ib̄a会在共产主义被实施之时统统烟消云散」根本是无稽之谈。&lt;/p&gt;

&lt;p&gt;我晓得某个一直剥削着我的劳动成功的男人，而我一直着逆来顺受着这剥削。他总是把一块胡萝卜悬在我的面前，并许诺在我帮助了他之后，他会把我带到他的池塘那里，允许我从那里免费地取水来浇我的树。多年来，他都在像这样许诺我。&lt;/p&gt;

&lt;p&gt;我为这个家伙做了长达不知多少个小时的危险活，却没有得到任何回报。他总是什么都不给我，在我干完活之后就已经走人了。然后，在下一周的周六的早晨6点到来的时候他又按喇叭来把我给叫醒，为他的没有来把我带到池塘那里对我道歉，声称他太忙或者要去处理家里的要紧事，许诺他会在这周之内带我去。然后，在他对我发号施令之余，我又得去跑到悬崖边或者屋檐上去为他修管子。&lt;/p&gt;

&lt;p&gt;我之所以去做这些，是因为我，t̄a大爷的，是个因为自己的可笑的温和性格，而不能对人说「不」的墙头草。但是，每当我请求他去做什么事的时候，回应我的总是一阵凝寂的注视，或者唐突的话题转移，或者托辞圆场。上周我的车抛锚了，这使得我被迫必须徒步2个小时，来从山上下来。而他开着车径直地超过了我，甚至没有减速。当我之后再和他见面的时候，他又发下毒誓，宣称他当时根本没看到我，因为阳光太刺眼了。我点了点头，耸耸肩。&lt;/p&gt;

&lt;p&gt;共产主义不会阻止这个死骗子对我所做的剥削；不管在哪种经济制度之下，他都会需要去请人来替他修补他的易漏的管道、启动他的柴油机、修剪他的橄榄树的高枝、攀爬他的摇摇欲坠的暂时性建物。他仍然会说他在被溃疡给折磨着来对我求情，而因此我则会去干那些苦差事来让他免受自己做所会引发的病痛。他不会停止他的ďiao人行为，因为民主已经扎根于职场。只要他还在小心翼翼地避免所有工作，并令别人内疚，而去替他做那些事，那么他就不会去做互助。&lt;/p&gt;

&lt;p&gt;每当我去质疑红色无治主义者们的蕴积深虑的意识形态时，t̄a们总是会援引那本书来攻击我……跟这些人分享我作为一个原民无治主义者的观点是相当困难的；t̄a们敌视所有不认可t̄a们的豪华工业化作风、不认可t̄a们试图民主化这种作风来让自己受益更多。&lt;/p&gt;

&lt;p&gt;在t̄a们冲着我「反动的作风主义者」和「臭原原人」的叫嚣之中，我试图向t̄a们解说我的观点。我看到了这世上的苦痛并且想要去弄懂t̄a。我不满足于就这么跟t̄a说一句拜拜，然后转而去紧抓不放幻丽的乌托邦意识形态，t̄a就是被设计来鼓动欧洲的厂工，并鼓动了近两百年的。&lt;/p&gt;

&lt;p&gt;那座我在里面工作十年有余的仓库并不会在我被授予民主之力时神奇地拥有解放性。t̄a将会仍然充斥着缓慢地致我死亡的杀虫剂。&lt;/p&gt;

&lt;p&gt;不用问，有些无共人肯定会一本正经地用相当于「不对，无治共产工业社会肯定是乌托邦，因为克鲁泡特金这么说过」来回应这篇文章。t̄a们所援引的语录将会来自一大堆文献，其对我而言不过是一些早已死亡的欧洲哲学家对工业平等主义的空洞许诺。我真正地被那种思维方法搞得没耐心了。这跟哪个7岁的人士试图通过坚称「因为爸爸这么说过…」来在争辩中获胜没什么两样。但是当一切都取决于此的时候，绝大多数红色分子确实会那样做。援引自己的英雄，热切地盼望t̄a们的话语有朝一日会如愿地被证实。正是那希望让t̄a们在其文明开化的痛苦生活焚毁着世界之余继续前进下去。「一旦我们有了职场民主，所有苦难就都会消散。」这些悲哀的，迷醉的，充满着希望的灵魂。&lt;/p&gt;

&lt;p&gt;我所知的一切都在告诉我，工业不能被弄成「绿色」，就像资本主义不能被弄得合乎伦理。历史上的所有农业工业社会都是导向引向生态灭绝，和t̄a们自己的最终的崩溃的。当你开采了物资，燃烧了汽油，量产了货物并把t̄a们送到了亿万人的手中时，你就已经对生态系统造成了不可逆的破坏。无共人并不是魔法生物，能够因为自己的“善”或“平等主义”来以某种方式逃避这个后果。&lt;/p&gt;

&lt;p&gt;如果真地有人尝试无治共产主义，那么半数的“奥妙”会被指为幻象、不成熟、无法在工业社会中实行而被抛弃。为了让体制能正常运转，一定会有人做出妥协。共产主义宣告了很多。但每当这些判断在现实生活的情景下被尝试时，几乎没有一个能带来成果，因为：&lt;/p&gt;

&lt;p&gt;1)资源并非无限。&lt;/p&gt;

&lt;p&gt;2)工业产出有很高的“隐藏”的代价，而最重要的是：&lt;/p&gt;

&lt;p&gt;3)工作并非出自自愿。&lt;/p&gt;

&lt;p&gt;不管你发了几遍誓，声称自己将让劳动民主化，仍不会有人因为自己真正愿意而工作的。t̄a们之所以现在在工作，是因为体制需要t̄a们去为活命而这么做。不管哪种程度的民主都会不会让体制停下来，让t̄a不再向所有在t̄a窒绝着气息的墙壁里的人昭彰自己的治权。当工业文明会在我们选择抵抗t̄a的统治时继续围堵并饥杀我们，消灭领土之间的权力是毫无意义的。&lt;/p&gt;

&lt;p&gt;之所以文明人为生产消费品而劳动，是因为体制不给给t̄a们其他的让t̄a们得以生存的选项一个“共产社会”里仍然在工厂或仓库工作一个只有一种可能性：是体制强迫着t̄a们去这么做的。自由的狩猎采集者不会自愿放弃自己的自由而去守在流水线旁，按着按钮来让别人能拥有玉米片、除草剂和AAA电池。把这强加于人是需要支持着工业体制的驯化和暴力、饥杀的共同胁迫的。&lt;/p&gt;

&lt;p&gt;工业很明显就是一种治权，而无治共产主义理论并没有意识到这一点。无治共产主义不过是改良文明的暴政，让t̄a能微笑得狡黠的一种尝试。这是无治主义版本的巴拉克奥巴马：许诺带来改变但是还是让老套上演，还要求你去为之庆贺。&lt;/p&gt;

&lt;h3 id=&quot;夺取毁灭资料然后t̄a大爷的把t̄a烧个稀巴烂&quot;&gt;夺取毁灭资料！（然后t̄a大爷的把t̄a烧个稀巴烂…）&lt;/h3&gt;

&lt;p&gt;无共人坚称在无治共产社会里「人们只会选择制造自己所需的东西」。「所需的」这个词根本没有意义。任何人都可以去把任何东西定为必须品。这正是工业化共产主义无法去与无治真正兼容的原因：所有的一切都会被驯化了的人们定为所需品，不论这些东西多么地滋孕威权。如果能让自己这么消费下去，无治消费者们会乐意地把从杀虫剂到屠宰场、汽车厂的一切都定义为“所需品”。这正是民主的力量。公社所采取的任何论述都将变为官方的、受了批准的言论，而任何对此提出质疑的人都会被视作逆反者、危险分子和对秩序和社会情理的威胁。&lt;/p&gt;

&lt;p&gt;这种「所需的工业」的论述实在很像许多红色“无治主义者们”一直在进行的论述：都是在维护t̄a们所贪恋的包括国家、监狱和警察在内的所有的治权。&lt;/p&gt;

&lt;p&gt;一般来说，t̄a们就只是在把这些治权更名为「公社」，「社会再融入中心」或者「和平守护者」，并心满意足地觉得自己已经创造了真正的变革。没意义的。驯化了的人们不会让自己去览遍t̄a们所继承的精工细作的使人陌离的世界。几乎没有文明人乐意于失去t̄a们自己所认为的巨大舒适：这由工业文明一点一滴的浸润而来的东西。&lt;/p&gt;

&lt;p&gt;哪怕t̄a们主动去认识到这些「舒适」实际上是在狠狠地圧杀t̄a们自己和这星球上的一切，只要t̄a们没有去直接抗拒这些舒适，t̄a们仍然会围绕着改良这些「舒适」被创造、分配的方法，去谋布起精详蔚丽的计划。这些计划在被解构、被去狗屁化之后基本上就是把「无治」这个词加到一切的前面，然后就此去相信：啊，一切都好起来了…因为全都被无治化了嘛。&lt;/p&gt;

&lt;p&gt;人在没有工业和农业的情况下兴荣了数千年。文明则已然导致了这星球上的一切的灭绝。99%的工业产品并非是在被人类所「需」，而是被人类所欲。&lt;/p&gt;

&lt;p&gt;当发觉到自己的手机、玉米脆和洗涤机的生态破坏力时，无共人并不会立即决定放弃t̄a们。t̄a们只会给一切挂上「所需品」「生态友好」或「绿色」的标签然后撒手、扬长。而我们则会被要求继续干我们痛苦的工作，还要爱上t̄a，因为现在，t̄a是（有着无治剥削和无治奴役的）无治社会里的无治工作。&lt;/p&gt;

&lt;p&gt;让人在矿坑和工厂里组建那些被「人民」所定为「所需」的消费品时，巨大的治权力将会是必须的，而就在治权力被引入的这一刻，一种名字并非「资本主义社会」的又一个版本的资本主义社会便诞生了；t̄a正如「共产主义」俄罗斯，「共产主义」中华和「共产主义」北朝鲜。一丝一毫的共产状态都不会留存在工业文明碾碎万物所留下的尘埃里。“无治共产主义”并不会改变那种结局的到来。贪恋着威权主义的工业文明、工人主义和被无共人大体上判定为「正当」的诸多治权的人口中的反治权的宣言听上去十分空洞。&lt;/p&gt;

&lt;p&gt;受组织的大众社会必然会被官僚机构所浸淫；这即是工业共产主义并非牢不可破的原因，这即是为什么每当t̄a被施行时，t̄a都会被体现为恶横的集体资本主义（比起原汁原味的资本主义，集中的权力在这种社会形式下更为泛滥）。官僚组织会迅速地化形为国家；可以确定的是，这个社会也就不再是共产主义的了。但是，当然，t̄a会继续把自己称作「共产主义的」，以此来确保资本主义和共产主义之间的区分微如细丝，从而让人们不能想象一种比残暴的工业废土（我们所降生到的地方）更好的世界。&lt;/p&gt;

&lt;p&gt;任何分配资源、对人加以警督的体制，在实际上就是国家，无论t̄a标榜自己为什么。&lt;/p&gt;

&lt;p&gt;所有对工业社会的实行都已自证无法解放人们；相反，t̄a让t̄a们的生活随着工业主义的愈演愈烈而越加地痛苦；而声称「在工业化体制的前头加上「无治」，就能让事情有所不同」实在是太t̄a大爷的搞笑了。&lt;/p&gt;

&lt;p&gt;共产主义从来就没有成功地解放我们：历史上如此，在未来亦然如此——宣称自己优于其他共产主义者，宣称自己的无共同志们都会拿喷枪把所有烟囱喷得鲜绿并不会在一瞬之间招来成功。&lt;/p&gt;

&lt;p&gt;如果社会是围绕着诸如工业主义，和民主这些威权主义体制所构建的，那么威权主义的举止就的确只会一遍又一遍地被重复下去。之所以马克思的和克鲁泡特金的共产主义都是围绕着这些体制的，是因为他们的意识形态是需要人们去被官僚所支配的。无关乎那官僚具体是去集中化的民主官僚，还是集中化的党团官僚。结果是相同的：权治、支配。&lt;/p&gt;

&lt;p&gt;如果没有这种官僚机构，社会会陷入无治状态。没错，喜人的，妙极的，解缰的无治：所有红色分子所恐惧的，&lt;em&gt;那个&lt;/em&gt;让t̄a们无法再强制地把社会和人给强扭成符合自己的圣严的意识形态的，、让其无法把自己的意识形态强加到社会和人之上的东西。被困在小小的无害箱里，被一滴滴地滴落的杀虫剂和高果糖玉米糖浆所饲育，驯化了的人们劳动着，消费着、消费着、消费着，然后死亡。&lt;/p&gt;

&lt;p&gt;这不是生活。这不是无治。这是一场清醒的噩梦，一个我们全都被彻底洗脑，以至于相信了t̄a可以被容忍的，极恶的地狱世界。（并非厂主的）厂工对毁灭资料的控制是停不下这场生态灭绝的。&lt;/p&gt;

&lt;p&gt;像所有红色分子所梦寐以求的那样去掌控工厂、去民主化t̄a的运作，是完全无法把我们拯救于暴力、痛苦、陌离化，还有最终的灭绝的。&lt;/p&gt;

&lt;p&gt;要毁灭治权只有一个方法：在工厂吞噬所有残留于这颗星球的物种之前，把工业毁灭掉。&lt;/p&gt;

&lt;p&gt;我们的生态系统崩坏着；我们若要在若干年后到来的事态中存活，唯一的机会即是粉碎每一个工厂、关闭每一个港口、砍断每一条道路，直到文明归于废墟。&lt;/p&gt;

&lt;p&gt;但是，说实在的，我们不会去这么做哦。我们会去看电视，会去啜饮冰茶，我们会去等待结束的那一刻啊。我会继续静静旁观下去，看着本地面包师把最后一片野地伐为白地呀。&lt;/p&gt;

&lt;p&gt;这颗星球可能会怎样怎样地在未来的几千年里恢复，那时新演化出来的生物可能比现在的沙漠制造者们更合道理吧。这可是我紧抓不放的最后的希望啊。&lt;/p&gt;</content><author><name>ziq</name></author><summary type="html">几年以来，我都在看着一个人开着他的皮卡车，驶入我附近的森林，砍掉所有未被立法保护的树——也就是：松树、橡树以外的所有树。</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/3aVzRzG.png" /><media:content medium="image" url="https://i.imgur.com/3aVzRzG.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">《反對統一》</title><link href="https://agorahub.github.io/pen0/heros/1920-10-10-MaoZedong-a1_c-against-unification.html" rel="alternate" type="text/html" title="《反對統一》" /><published>1920-10-10T11:00:00+07:00</published><updated>1920-10-10T11:00:00+07:00</updated><id>https://agorahub.github.io/pen0/heros/MaoZedong-a1_c-against-unification</id><content type="html" xml:base="https://agorahub.github.io/pen0/heros/1920-10-10-MaoZedong-a1_c-against-unification.html">&lt;p&gt;中國的事，不是統一能夠辦得好的，到現在算是大明白了。中國也不是全無熱心國事的人。這些熱心國事的人，也不是全然沒有知識和能力。然而辦不好者，中國之人，太沒有基礎，太沒有下層的組織。在沙堵〈渚〉上建築層樓，不待建成，便要傾倒了。&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;中國二十四朝，算是二十四個建在沙堵〈渚〉上的樓，個個要傾倒，就是因為個個沒基礎。四千年的中國只是一個空架子，多少政治家的經營，多少學者的論究，都只在一個空架子上面描寫。每朝有幾十年或百多年的太平，全靠住一個條件得來，就是殺人多，流血多。人口少了，不相殺了，就太平了，全不靠有真實的基礎。因此我們這四千年文明古國，簡直等於沒有國。國只是一個空的架子，其內面全沒有什麼東西。說有人民罷，人民只是散的，“一盤散沙”，實在形容得真冤枉！中國人生息了四千多年，不知幹什麼去了？一點沒有組織，一個有組織的社會看不見，一塊有組織的地方看不見。中國這塊土內，有中國人和沒有中國人有什麼多大的區別？在人類中要中國人，和不要中國人，又有什麼不了的關係？推究原因，吃虧就在這“中國”二字，就在這中國的統一。現在唯一救濟的方法，就在解散中國，反對統一。&lt;/p&gt;

&lt;p&gt;中國人沒有科學腦筋，不知分析與概括的關係，有小的細胞才有大的有機體，有分子的各個才有團體。中國人多有一種拿大帽子戴的虛榮心，遇事只張眼望著前頭，望著籠統的地方。大帽子戴上頭了，他的心便好過了。現在的和議，就是這樣。一些人捧著一個“和議”，北跑到南，南跑到北，沒希望的時候，便皺著眉，有一點希望，便笑起來了。我是極端反對和議的，我以為和議是一個頂大的危險。我的理由，不是段琪瑞的統一論〔１〕，也不是章太炎孫洪伊的法律論〔２〕，我只為要建設一個將來的真中國，其手段便要打破現在的假中國。起碼一點，就是南北不應複合〔３〕，進一層則為各省自決自治。&lt;/p&gt;

&lt;p&gt;各省自決自治，為改建真中國唯一的法子，好多人業已明白了。這是這次南北戰役〔４〕的一個意外的收果。現在雖然只有湖南，廣東，江蘇，湖北幾個省發動，事勢必然成為一道洪流。全國各省，都將要納到這個流裡，是一個極可喜的現象。現在所要討論的有兩個問題：一個是各省自治內部的事，即如何促使各省自治成立；一是各省自治外部的事，即如何將妨礙各省自治的障礙物，減殺其效力或阻止其進行。&lt;/p&gt;

&lt;p&gt;關於前一個問題，我有二個意見：（一）像湖南廣東兩省用兵力驅去舊勢力的，算是一種革命，應由各該革命政府，召集兩省的“人民憲法會議”〔５〕，制定“湖南憲法”及“廣東憲法”，再依照憲法，建設一個新湖南及新廣東。這兩省的人民最要努力。其憲法要采一種澈底革新的精神，務以儘量發揮兩省的特性為標準。（二）像湖北江蘇兩省，不能有革命的行動，只好從鄂人治鄂蘇人治蘇（省長）一點入手，等到事權歸了本省人，便進而為地方自治的組織。以上二種方法，各依各的情勢去改造。於前一種可以樹各省自治的模範，實有“國”的性質，可實行一種“全自治”，所以最有希望。於後一種，雖然暫時只能實現“半自治”，然根據這種自治，便可進而做廢督運動。只要督軍廢了，則全自治便即刻到了手了。方法雖然和平一點，不十分痛快，然為適應環境，采這種方法，也是好的。&lt;/p&gt;

&lt;p&gt;關於如何除去各省自治的障礙物，我以為這障礙不在督軍，而在許多人要求的“統一”。我以為至少要南北對立。這是促成各省自治的一大關係點。倘使統一成了，新組國會，制定憲法，各省自治，必多少要受憲法束縛（無論中央政府永辦不好），像湖南廣東，便斷不能發揮其特性。又人才奔赴中央政府，地方必有才難之歎。更有一個大不好處，假如中央政府成了，全國視線，又都集注中央，中國人看上不看下務虛不務實的老癖必要大大發作，而各省自治，又變成不足輕重的了。我覺得中國現在的政象，竟如清末一樣，國人對之，不要望他改良，要望他越糟越壞。我看此際尚未壞到極處，我們不能用自力加增其壞度，卻盡可不必替他減少壞度。我們最好采不理主義，和議再不要說了，國民大會解決國事之說〔６〕，再不要提倡了。要提倡國民大會，也要如張東蓀先生的主張，用國民大會去解決省事。&lt;/p&gt;

&lt;p&gt;胡適之〔７〕先生有二十年不談政治的主張，我現在主張二十年不談中央政治，各省人用全力注意到自己的省采省們羅主義，各省關上各省的大門，大門以外，一概不理。國慶〔８〕是慶中華民國，我實在老不高興他。特為趁這國慶，表示我一點反對統一的意見，而希望有一種“省慶”發生。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;注釋：&lt;/p&gt;

&lt;p&gt;〔１〕段祺瑞，北洋系長老。&lt;/p&gt;

&lt;p&gt;〔２〕章太炎，即章炳麟（１８６９—１９３６），字枚叔，號太炎，浙江余杭人。中國近代民主革命家、學者。時竭力主張聯邦制，主張各省迅速制定正式憲法，不能滿足于臨時憲法。孫洪伊（１８７０—１９３６），字伯蘭，天津人。早年為袁世凱幕僚。１９１１年任直隸諮議局議員，參與立憲活動。１９１６年在段祺瑞內閣中先後任教育總長和內務總長。後參與組織憲法商榷會和民友社。時竭力主張“由人民組織地方政府，施行地方政治”，“以憲法會議討論之地方制度，參合試行。”&lt;/p&gt;

&lt;p&gt;〔３〕南北不應複合，意為當時的中國不應再行“南北議和”、“南北統一”。&lt;/p&gt;

&lt;p&gt;〔４〕南北戰役，指１９１７—１９１９年間南方護法軍與北洋軍閥之間的戰爭。&lt;/p&gt;

&lt;p&gt;〔５〕召開人民憲法會議，是毛澤東、彭璜、龍兼公等人的一種政治主張。他們曾提出《由“湖南革命政府”召集“湖南人民憲法會議”制定“湖南憲法”以建設“新湖南”之建議》。&lt;/p&gt;

&lt;p&gt;〔６〕指當時吳佩孚等人提出通過召開國民大會解決一切問題的主張。&lt;/p&gt;

&lt;p&gt;〔７〕胡適之，即胡適。&lt;/p&gt;

&lt;p&gt;〔８〕１９１１年１０月１０日武昌首義後，中華民國建立。１９１２年９月２８日北京臨時政府臨時參議院議決，定１０月１０日為中華民國國慶日。&lt;/p&gt;</content><author><name>毛澤東</name></author><summary type="html">中國的事，不是統一能夠辦得好的，到現在算是大明白了。中國也不是全無熱心國事的人。這些熱心國事的人，也不是全然沒有知識和能力。然而辦不好者，中國之人，太沒有基礎，太沒有下層的組織。在沙堵〈渚〉上建築層樓，不待建成，便要傾倒了。</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/vWFCjYC.png" /><media:content medium="image" url="https://i.imgur.com/vWFCjYC.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>