---
layout: post
title : "大語言模型可以理解時空？"
author: "討厭鬼"
date  : 2023-10-09 12:00:00 +0800
image : https://i.imgur.com/dD6zGaE.png
#image_caption: ""
description: ""
---

有人認為[「大語言模型(LLM)可以推論時間與空間問題」](https://arxiv.org/abs/2310.02207)。但身為讀過一點心智哲學的人，還是忍不住要提問：

「一個東西可以推論時間與空間」究竟是什麼意思？

<!--more-->

這個問題內藏了兩個沒說清楚的關鍵概念：

1. 「時間與空間」是什麼？

2. 「推論」又是什麼？

物理學認為時空是維度，是事件與物體之間的相對關係。從這個角度來看，正確整理了事件的前後順序與相對距離，的確可以稱為對時空做出了推論。

但問題是，時空不只是一種測量方式。事件需要量測，但我們如何進行量測？我們的心智如何對量測產生預期，進行編碼？

白話地說，我們怎麼知道時空存在？如何知道事件有先後，空間有前後左右上下？如何用這些屬性去整理蒐集到的資料？

哲學認為其中某些問題是無法回答的，尤其因果、時間、空間這類的概念，是我們心智的認知框架，我們在用感官與行動獲得經驗時，就以這些認知框架去「編碼」經驗，故不可能與經驗分開。

白話版，就是我們每個人都帶著因果與時空的有色眼鏡，而且摘不掉。我們所談論的一切經驗，所做的一切測量，都被這種眼鏡染色，被這種框架歸類。

所以LLM可以理解時空，可以做時空的推論嗎？

如果你問的是「LLM能不能將我們獲得的經驗資料，進行整理歸納，使其符合我們認知時空的方式」，答案是當然可以。

這不是因為LLM多厲害，而是因為LLM是一種機器學習，是用模式識別的方式來習得資料之間的相關性。資料背後的脈絡越詳盡，或者資料本身越是發生在某些時間或某些空間中，LLM當然就越能找到該資料與其他資料之間的相關性、相對關係，藉而將資料定位在(人類認為的)正確的時空位置。

但如果你問的是「LLM能不能以我們認知時空的方式，蒐集並整理資料，使其符合我們的整理方式」，我就持保留態度。因為這牽涉到「推論」和「理解」是什麼。

雖然有點骨董，但接下來請容我使用語言學常用的「內涵」與「外延」。我們叫機器「理解」一個東西時，通常是要機器掌握那個東西在世界中適用於那些事物，不適用於那些事物，以及那個東西與其他東西之間如何互動。這是語言學所謂語意的「外延」，是事物與行動之間的互動關係。

但幾乎沒有人會說語意只等於外延，更是幾乎不會有人說人類完全是靠外延來了解語意。我們在學習與使用語言時，還會有一種難以說清的，心裡覺得什麼就是什麼的標準。我們覺得「蘋果」是被賈伯斯咬了一口的3C產品(喂)，「肯德基」是一家很會做蛋塔的公司(一定是這樣!)，「哲學」是一種只會把事情講複雜毫無屁用的空談(這篇是很好的例子。只有讀哲學的人才會自以為是地寫這麼無聊的文章)。

這些標準就叫做「內涵」，是我們使用語言和概念時的指引，很多時候甚至是唯一的指引。我自己通常就是根據內涵來行動或思考，而非先去查詢每個概念或語詞的意義，我猜絕大多數人應該也一樣。

但問題是，內涵是怎麼來的？這個問題就牽涉到「什麼是理解」的關鍵。

只要想一下應該就會發現，內涵不可能單純來自學習外延。即使不管這會造成循環定義，光是「要把哪些外延納入內涵來學習」就會遇到問題。番茄是一種蔬菜嗎？土星是一種湯嗎？次方是一種運算符號嗎？香蕉是一種漿果嗎？中華民國是國家嗎？

(給瘋狂的克蘇魯信徒：以上答案都是「YES」)

但如果內涵不只來自學習外延，內涵哪來的？來自人類的理解。

哲學普遍認為人類與大多動物具有「意向性」，也就是以自己出發，指涉各種事物的能力。我們可以指涉披薩上出現的鳳梨、高壓電線上倒掛的風箏、不斷下降的股價、甚至抽象的數字或流程。

我們可以指涉土星，可以指涉湯，所以當有人說土星是一種湯，我們會覺得對方真是聰明絕妙(最好是啦！)

但LLM有這種能力嗎？訓練LLM的方式應該是沒有，但被訓練成LLM的電腦有沒有？

我不知道，但目前好像還沒看到跡象。有任何線索還請分享，我超有興趣。

這能力在我們討論「時空」、「因果」這類概念時，會特別重要。

因為如果至今的哲學理解是對的，時空與因果的認知框架，就比任何概念和經驗都更早存在。我們用這種框架去跟世界互動，去指涉所有經驗、概念、事物，去蒐集每一筆資料以及賦予資料意義。因此，人類都不知道除了用這種方法以外，關於時空與因果的資料還能如何整理。

但LLM似乎沒有這種認知框架，本身似乎也沒有指涉事物的意向性。它要如何整理關於時空的資料，或者要如何理解人類世界的整理框架？

我不知道它可不可以，也不知道如果它可以的話將會怎麼做。所以在這部分暫且保留。

請注意，這並不表示LLM整理資料的時空屬性時會「出錯」，因為時空屬性是人貼到資料上的，以及人根據時空框架蒐集資料時產生的，前者已經帶了框架，後者不但帶了框架而且更是relational，LLM要識別模式應該沒什麼問題。

而且絕大多數的資料問題，都可以用靠著這種識別模式與脈絡的方式來解決。LLM的處理能力應該會相當強大，相當可信。

但我們得注意，這些都只是「處理」資料，而非「認知」或「推論」那些資料。認知與推論不只是根據既有編碼的方式來編碼資料，也不只是根據既有概念之間的相關性(也就是概念的使用脈絡)來調整每個概念之間的連結與距離。認知與推論經常需要使用語言的內涵，經常必須指涉對象，很可能會需要意向性。

在我們還沒發現LLM或任何形式的電腦，有能力指涉事物，有先驗的框架去整理資料之前，我們最好不要讓電腦獨立去進行我們稱為「推論」或「認知」的事情，或者至少不要把它們處理的結果太當真，因為很可能許多「見人類所未見」的強大處理結果，最後都只是幻覺。

(這在某些領域可能相當重要，例如犯罪、情蒐、金融、總體經濟。因果與時空的推論錯誤可能造成嚴重的傷害)

但電腦即使不具備先驗的認知框架與指涉事物的能力，依然可以準確地根據人類至今以來認知框架建構的龐大資料庫，去進行衍伸運算。這會像是人類(而且是全體人類)獲得了很強大的影分身能力，能夠以更快的速度更廣的範圍去蒐集資料、處理蒐集到的資料。許多過去需要太長時間太多人力去做的整理與運算，未來很可能都能做。

所以我至今依然認為，在電腦還沒有發展出一些至今難以解釋的認知功能(意向性、主體性、qualia等等)之前，我們在設計電腦的功能與服務時，都應該盡量讓電腦與人類互補，成為人類的衍伸，去擴大人類的能力(在這方面主要是記憶、資料整理、語言協助與轉換能力)，而非試圖與人類競爭。讓電腦去「模仿」人類的能力，不僅會破壞人類的經濟環境因而不道德，更會因為搞錯了「認知」是什麼而事倍功半，徒然耗費能源製造汙染。

<!--END-->