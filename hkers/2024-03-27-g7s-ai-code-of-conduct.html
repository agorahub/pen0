<!DOCTYPE html>
<html lang="en">

	<head>
		<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1" />


	<title>G7’s AI Code Of Conduct · The Republic of Agora</title>


<meta name="description" content="It is the G7’s chance to mature the code of conduct to confer a presumption of conformity to the European Union’s AI Act and to enhance AI regulatory interop...">

<link rel="stylesheet" href="https://agorahub.github.io/pen0/assets/dark.css">
<link rel="icon" href="https://agorahub.github.io/pen0/assets/favicon.png">
<link rel="apple-touch-icon" href="https://agorahub.github.io/pen0/assets/touch-icon.png">
<link rel="stylesheet" href="https://agorahub.github.io/pen0/assets/common.css">

	<link rel="stylesheet" href="https://agorahub.github.io/pen0/assets/post.css">
	<script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.min.js" type="text/javascript"></script>


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="canonical" href="https://agorahub.github.io/pen0/hkers/2024-03-27-g7s-ai-code-of-conduct.html">
<link rel="alternate" type="application/atom+xml" title="The Republic of Agora" href="https://agorahub.github.io/pen0/feed.xml" />

<!-- Google Font -->
<link href="https://fonts.googleapis.com/css?family=UnifrakturMaguntia" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Libre+Baskerville|Mansalva&display=swap" rel="stylesheet">




  <!-- change your GA id in _config.yml -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-166928354-2', 'auto');
  ga('send', 'pageview');
  </script>


		
	</head>

	<body>

		<div class="head">
  
  <div id="masthead">
    <h3><a href="https://agorahub.github.io/pen0/">The Republic of Agora</a></h3>
  </div>

  
</div>


		<div class="content">
			<article>

  <header>
    <h1>G7’s AI Code Of Conduct</h1>
    <br>
    <div class="item">
      <img  src="https://i.imgur.com/RJmR3p8.jpeg">
    </div>
    <h3>Advancing the Hiroshima AI Process Code of Conduct under the 2024 Italian G7 Presidency: Timeline and Recommendations</h3>
    <h4>Gregory C. Allen and Georgia Adamson | 2024.03.27</h4>
  </header>
  <div class="item">
    <p><em>It is the G7’s chance to mature the code of conduct to confer a presumption of conformity to the European Union’s AI Act and to enhance AI regulatory interoperability at the G7 this year.</em></p>

<excerpt />

<h3 id="introduction">Introduction</h3>

<p>Over the past five years, the G7 and its member states have made significant progress in specifying ethical principles for AI. Advancing global AI governance in 2024 demands translating these high-level principles into concrete practices for AI developers and government organizations. Rather than address this challenge in isolation, G7 leaders stated in their 2023 Leaders’ Communiqué they would work together and with others to “advance international discussions on inclusive artificial intelligence (AI) governance and interoperability to achieve our common vision and goal of trustworthy AI, in line with our shared democratic values.” The March 2024 Industry, Technology and Digital Ministerial declaration recently reaffirmed this commitment, stressing “the importance of international discussions on AI governance and interoperability” with like-minded partners and developing countries.</p>

<p>The work of the G7 has already had a tangible impact in productively shaping the domestic AI regulatory approach of multiple G7 members, including the United States (through the 2023 AI executive order), Japan (the updated AI regulatory guidance), and the European Union (the AI Act). In conversations with CSIS, government officials from each of these members stated that the G7 was substantive and helpful to their regulatory efforts. Notably, members of the European Parliament involved in drafting the EU AI Act told CSIS that some sections of the act were directly inspired by the Hiroshima AI Process (HAIP) Code of Conduct the G7 published in October 2023.</p>

<p>One such section of the EU AI Act is Article 52, which outlines transparency obligations for Global Partnership on Artificial Intelligence (GPAI) models above a computational threshold of 1025 floating point operations per second (FLOPS). According to Article 52, the European Union’s AI Office shall “encourage and facilitate the drawing up of codes of practice at Union level as an element to contribute to the proper application of this Regulation, taking into account international approaches.” Industry developers are directed to coregulate these codes of practice by collaborating directly with the European Commission on this issue.</p>

<p>Members of the European Parliament told CSIS they believe the HAIP Code of Conduct is the best available starting point for what will ultimately become the EU AI Office’s officially recognized codes of practice for certain GPAI models. Parliament members stated their support for maturing the G7’s code of conduct to a degree that meets EU requirements, such that providers of GPAI models who demonstrate compliance with the G7’s HAIP Code of Conduct would enjoy a “presumption of conformity” to the EU AI Act’s GPAI codes of practice.</p>

<p>The European Union, while it has the sole final decision over the AI Act’s implementation, should be commended for its demonstrated commitment to interoperability, openness to international input during the codes of practice design process, and willingness to take advantage of the work already done under the Japanese 2023 G7 presidency. Maturing the code of conduct to confer a presumption of conformity to the EU AI Act would not only help the European Commission develop a key piece of regulation for GPAI models but also offer an opportunity for other G7 members to help shape language that will set an informative precedent for how global AI regulations are designed and implemented. Moreover, aligning the code of conduct to the European Union’s codes of practice would be hugely impactful for the G7’s stated goals of establishing interoperable AI regulations and broadening the dissemination of the code.</p>

<p>Even if the European Commission does not ultimately use the code of conduct to inform or stand in for the European Union’s official codes of practice, the G7 would still achieve a substantially more mature code by aiming to meet this ambitious goal. In its current state, the code of conduct’s 11 high-level principles are too vague for AI developers to subscribe to or implement without further specification. Translating these principles into monitorable and enforceable tasks for AI developers would therefore be a meaningful achievement alone. This process will require extensive input from the private sector to determine what is relevant, technically feasible, and reflective of existing industry best practices in AI governance. Cooperation with and public endorsement from a diverse group of leading international AI firms will also be needed to help to demonstrate the code’s building momentum within the AI industry. While maturing the code of conduct through these avenues and more would already fulfil one of the G7’s stated priorities for 2024, the G7 could go further by aligning the code of conduct with the European Union’s codes of practice to achieve its broader goals of enhancing regulatory interoperability and widening the adoption of the code of conduct.</p>

<h3 id="timeline">Timeline</h3>

<p>The expected timeline for EU AI Act implementation suggests that a draft version of the GPAI codes of practice must be ready by February 2025 (see Figure 1). Comparing the EU and G7 timelines highlights that the G7 code of conduct should be substantially elaborated by February 2025 if the European Union is to consider the code of conduct as a presumption of conformity to the European Union’s code of practice on GPAI models when the regulations take effect. This gives the G7 approximately 11 months from the writing of this white paper to mature the code of conduct ahead of the European Union’s February 2025 deadline. While the HAIP Code of Conduct could inform a later, updated EU AI codes of practice, meeting the February 2025 deadline would certainly have greater impact.</p>

<p><img src="https://i.imgur.com/UwRrl6E.jpeg" alt="image01" />
<em>▲ Figure 1: Expected EU AI Act Implementation Time Frame</em></p>

<p>The Italian G7 presidency therefore comes at a critical window of opportunity to substantially advance the HAIP and the interoperability of allied AI regulatory frameworks. The Italian presidency recently restated the G7’s commitment to maturing the HAIP and the code of conduct at the Industry, Technology, and Digital Ministerial Meeting in Verona and Trento on March 14 and 15, 2024. The ministerial declaration from this meeting promises to advance the HAIP outcomes on page 10, “including through expanding support and awareness among key partners and organisations, as well as increasing their involvement, as appropriate.” Specifically, per Annex 3, the G7 will develop monitoring mechanisms for assessing organizations’ voluntary implementation of the code of conduct, increase stakeholder engagement in maturing the code of conduct and its adoption, and collaborate with the Organization for Economic Cooperation and Development (OECD), UNESCO, and GPAI on challenges posed by AI systems. Progress on these issues will be presented at the leaders’ summit in June.</p>

<h3 id="recommendations">Recommendations</h3>

<p>Given the G7’s 2024 agenda for the HAIP and the European Commission’s deadline of February 2025 for developing the GPAI codes of practice, the Italian G7 presidency should strive to accomplish the following this year:</p>

<ol>
  <li>
    <p><strong>Continue working on the HAIP Code of Conduct after the March 15 ministerial meeting, including a second digital and industry ministerial meeting toward the end of 2024.</strong> Developing the code of conduct will take substantive effort from both G7 members and AI developers in the private sector and academia. CSIS supports the Italian presidency’s year-round approach to maturing the HAIP ending, with a second ministerial meeting showcasing the G7’s work toward the end of 2024.</p>
  </li>
  <li>
    <p><strong>Develop the HAIP Code of Conduct’s monitoring and evaluation mechanisms through the OECD.</strong> While the G7 has done excellent work on advancing AI governance principles thus far, its lack of permanent staff makes it challenging to continue this work alone in the long-term. The March Industry, Technology, and Digital Ministerial declaration indicates that the OECD will provide this missing institutional support to the G7 on the Hiroshima AI Process, continuing a long-standing partnership between the two fora.</p>

    <p>The OECD has a strong record of developing monitoring and evaluation mechanisms, which the G7 should draw on to meaningfully mature the code of conduct in 2024. Japan chairs this year’s OECD’s Ministerial Council, offering continuity between the G7 Hiroshima Process, which Japanese government officials continue to staff and support, and the OECD. Developing the code of conduct through the Ministerial Council and other OECD channels, including the Global Partnership on AI, will offer essential capacity and expertise to the 2024 G7.</p>

    <p>Close collaboration with the OECD would also offer a longer-term path to expand the HAIP beyond the G7, first to like-minded democratic market-driven economies among the OECD countries. The OECD could also serve as a first step in further expansion to a wider set of non-OECD countries through the OECD-hosted Global Partnership on AI, which includes countries such as Brazil and India.</p>
  </li>
  <li>
    <p><strong>Gather input from private sector AI organizations on the code of conduct through requests for comment and formalized convenings of relevant stakeholders.</strong> In a speech to the Italian government’s Digital Transition Committee in November 2023, Prime Minister Giorgia Meloni stated that establishing AI governance guidelines “does not mean working against companies” but instead “engaging in dialogue” between the public and private sector. Dialogue between relevant stakeholders is indeed essential for ensuring the code of conduct is translated into specific actions that are technically feasible and reflect the rapidly changing capabilities of advanced AI systems. To ensure that this dialogue remains consistent and constructive, input from private sector AI developers should be organized through specific initiatives such as requests for comment, working groups, and feasibility studies.</p>
  </li>
</ol>

<p>With these recommendation in place, CSIS hopes the following occur by the end of the Italian G7 presidency:</p>

<ul>
  <li>
    <p>G7 members and EU AI Act officials expand, finalize, and accept the HAIP Code of Conduct language.</p>
  </li>
  <li>
    <p>A substantial number of companies support the drafting of and publicly subscribe to the code of conduct.</p>
  </li>
  <li>
    <p>The OECD serves as the principal forum in which to develop monitoring and transparency functions of the code of conduct as necessary.</p>
  </li>
  <li>
    <p>By late 2024 or early 2025, there is a clear path to expanding the code of conduct beyond the G7 and OECD forums, including non-G7 and OECD countries potentially through the OECD’s Global Partnership on AI forum.</p>
  </li>
</ul>

<hr />

<p><strong>Gregory C. Allen</strong> is director of the Wadhwani Center for AI and Advanced Technologies and senior fellow with the Strategic Technologies Program at the Center for Strategic and International Studies (CSIS) in Washington, D.C.</p>

<p><strong>Georgia Adamson</strong> is a research assistant with the Wadhwani Center for AI and Advanced Technologies at CSIS.</p>

  </div>

</article>

		</div>

	</body>

	
	
	<p class="love">
		Made with <i class="fa fa-heart"></i> by <a href="https://github.com/agorahub">Agora</a>
		<button class="hidden scheme"><i class="toggle d-adjust"></i></button>
	</p>
	
	<script src="https://agorahub.github.io/pen0/assets/auto-dark.js"></script>

</html>
